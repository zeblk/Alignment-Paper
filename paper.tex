
\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=0.9in]{geometry}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{changepage}
\usepackage{pdflscape}
\usepackage{authblk}

\usepackage{wrapfig}
\usepackage{tcolorbox} % Required for the pretty box

\usepackage{tabularray}

\usepackage[labelfont = bf]{caption}
\captionsetup{font=footnotesize}

\usepackage[sort]{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}} %Citation-related commands

\newcommand{\zeb}[1]{{\footnotesize\textcolor{red}{[Zeb: #1]}}}

\title{Living Alignment}

\renewcommand\Authfont{\normalsize}
\renewcommand\Affilfont{\footnotesize}

\author[1]{Zeb Kurth-Nelson\thanks{Equal contribution}}
\author[2]{Steve Sullivan\protect\footnotemark[1]}
\author[3]{Nenad Tomašev}
\author[3]{\authorcr Joel Leibo}
\author[4]{Matthew Nour}
\author[5]{Marc Guitart-Masip}

\affil[1]{Prefrontal.ai, London, UK}
\affil[2]{Oregon Health and Science University, Portland, OR}
\affil[3]{Google DeepMind, London, UK}
\affil[4]{Microsoft AI, London, UK}
\affil[5]{Karolinska Institutet, Stockholm, Sweden}

\date{\normalsize\today}

\begin{document}

\maketitle

\vspace{20pt}


\begin{adjustwidth}{35pt}{35pt}
\begin{center}
\textbf{Abstract}
\end{center}

There is broad agreement that the goal of AI alignment is to promote futures full of health and flourishing. But our understanding of what exactly this means and how to achieve it remains poor. In this paper, we look to life for inspiration. We observe that living systems are healthy and full of open-ended potential when they form intricate semi-permeable boundaries that expand internal space and defy simplistic descriptions. Living entities deepen their individual perspectives, becoming sensitive to more and more nuance of their context, and those new perspectives enter into relationship with other entities. Fundamentally new forms emerge over time. This process supports a many-scaled web of complexity that is difficult to completely capture with formalism. With these principles in mind, we turn to the alignment problem. We suggest that the semi-stable creative dynamics of life are at the heart of what we most deeply value. We cast some well-studied problems in alignment as special cases of our framework, then examine situations where the framework goes further. Finally, we sketch out a preliminary view of how aligned AI systems can participate in rather than overwhelm or collapse the subtlety of life.

\end{adjustwidth}
\vspace{30pt}


% cancer spreads, concentrated power reduces human welfare, invasive species choke out complex ecosystems

% surfacing paradoxes by juxtaposing incompatible things

% semi-permeable boundaries contextualize myopic forms as part of larger systems. 



% If you want to jump straight to alignment, it starts at Section~\ref{sec:alignment}. But those arguments will have more color if you read at least a few of the earlier sections first.

% Living systems adaptively adjust boundaries when structure is being flattened. 

% Sometimes homogenization is blending or averaging; other times it is winner-take-all or domination. 
% -- whether agentic like an organism, or non-agentic like the sodium concentration of an extracellular solution --


% Forces, ranging from simple diffusion to the will of an agent, cause excessive blending or overwriting of forms if left unchecked. When this happens, the richness of the world is collapsed.


% a kind of general relativity? lol. things are defined by their interactions... (`ontic structural realism'). or maybe relationships are forms too. getting too stuck in one pattern of relationship is getting stuck in a particular form. 

% each form or arrangement is lightly held. 

% \tableofcontents

In this paper, we study life to better understand how to design and relate to AI systems in ways leading to futures full of flourishing and health. Our approach is systems-oriented, with the hope that the ideas can be applied to reason not only about the present world, but also about possible future worlds where humanity and AI may have changed substantially. Those future worlds may involve entirely new concepts and categories. We gravitate to ideas about alignment that generalize over such changes.


% We often anchor back to the idea of an AI system being `aligned to' human values. indeed this is the origin of the term `alignment'. But the concepts here are intended to be more general. It doesn't have to be an AI system alone that is aligned. We can talk about aligned human-AI systems, for example. We expect the boundaries and categories will change in the future. The point is to think about a future that is overall flourishing and positive, regardless of what kinds of unforseen functional units come to exist. 

% One consequence is that the lens of alignment can be flexibly used to look at not only AI in isolation, but also AI in relationship with humanity, or indeed any way of drawing lines to define a system.

Section 1 looks across a variety of living systems and identifies a consistent theme. These systems are healthy and full of creative potential when they don't overcommit to particular partial forms, but instead maximize generativity at the knife edge of delicate, evolving interplay between diverse entities. Exquisitely tuned networks of semi-permeable boundaries -- where life is both the boundary and the thing being bounded -- protect against overcommitment. Boundaries are semi-permeable when they both \textit{limit} and \textit{permit} interaction. Limits ensure entities maintain their distinctiveness without getting overwritten or averaged to equilibrium; limits also encourage entities to deepen and generalize their own unique perspectives. Equally important, permitting interaction means those rich and evolving individual perspectives can enter into relationship with other entities, situating them in a larger context. 

Section 2 applies this template to the alignment problem. We propose that the systems-level definition of health, creative potential and open-ended sensitivity to context is near to what we most deeply value and what we mean when we talk about flourishing in a sense that includes potentially radically different futures. We unpack a few specific problems in alignment to show how they can be viewed as special cases under our definition, then look at limits of those special cases to see why the broader framework is useful. A key takeaway will be that the alignment problem is inherently not formalizable, because alignment requires continued generation of and sensitivity to new forms and concepts.

Section 3 offers a preliminary outline of how the principles described in Sections 1 and 2 can be applied concretely and what a truly aligned future might look like.

% Any conceptualization of alignment is by our own definition not a final answer. In this spirit, we are not going to try to make an irrefutable logical argument or compel you to accept our perspective to the exclusion of others. Instead, throughout the manuscript we focus primarily on examples and leave it up to you to decide if our analogies are useful. We've tried to select terms -- like `form', `overcommitment', `collapse', `boundary', `groundedness' and `contextualization' -- whose everyday meaning is as close as possible to the ideas we want to describe. We hope that the examples will bring to life the shades of meaning we have in mind with each of these terms.




\section{Health in living systems}

\begin{center}
\textit{`Defying definition---a word that means ``to fix or mark the limits of"---living cells move and expand incessantly.'}\\*Lynn Margulis
\end{center}

\begin{center}
\textit{`When forced to work within a strict framework, the imagination is taxed to its utmost--and will produce its richest ideas. Given total freedom the work is likely to sprawl.'}\\*TS Eliot
\end{center}

\begin{center}
\textit{`Nature's imagination is so much greater than man's, she's never going to let us relax.'}\\*Richard Feynman
\end{center}

A common motif across many kinds of living system is that health is related to avoiding collapse into simplistic rigid or random patterns, and instead maintaining a rich internal structure with many differentiated internal forms that relate to one another in diverse, dynamic ways. Stereotypy and rigidity are clasically pathological in physiological systems \citep{canguilhem1966normal, lipsitz1992loss, mackey1977oscillation, sterling1988allostasis}. In evolution, overspecialization and homogeneity make species brittle, leading to trouble especially when environments change \citep{van2004cope, simpson1944tempo, yachi1999biodiversity}. Excessive training for a physical discipline (e.g., extreme ballet) can negatively impact broader functional health \citep{jayanthi2013sports, warren1986scoliosis}. Institutions and civilizations that ossify in bureaucracy and rigid patterns become dysfunctional \citep{weber1905protestantische, merton1940bureaucratic, olson1982rise}. Cognition operates best when neural circuits maintain flexibility to enter different modes, rather than collapsing into narrower patterns \citep{deco2012ongoing, waschke2021behavior, hellyer2015cognitive}. In statistics and artificial life, theorists argue that life operates best at the `edge of chaos' where it collapses neither into randomness nor excess regularity \citep{langton1990computation,kauffman1992origins, gell1994quark, crutchfield1994calculi}.

Living systems admit a remarkable 

In each of these examples, finding a balance between existing factors is necessary but not sufficient for healthy functioning. Simply avoiding extremes by itself, like settling on a middle ground or equal weighting, can be a dead-end. In the unsettled semi-stable dynamics of life, balance is a workspace and site of synthesis, not a forever-safe resting place \citep{stanley2017open, walker2004resilience, von1950theory,holling1973resilience,prigogine1984order,kauffman1992origins}. Avoiding overcommitment to any form -- where a form can be literally any pattern, including homogeneity or volatility -- maximizes sensitivity and creative potency.

Living systems generate new descriptions as they evolve (Stuart Kauffman). 


For an entity within a system, healthy functioning means maintaining sensitivity to context. Think of a stock trader who sells irrationally in a panic. Their fear drives an overly simplistic response: `the stock is crashing, get out!'. In excess attachment to this myopic frame, they miss the larger context: higher-order or longer-term aspects of the situation. At the same time, myopic frames are an absolutely necessary part of all living systems. Every entity is myopic or partial: it does not capture everything else in the world. The existence of these diverse myopic forms, all participating in larger contexts, is central to healthy functioning. The stock trader's fear might be a useful signal if held as part of a larger picture. Living systems function poorly when a myopic form runs amok without contextualization, overwhelming and collapsing the potent interplay of diverse parts. They function well when forms locally commit to their own identities but also participate in larger contexts. 

(Can we express better how life has to be this `irreducible' multi-scale complexity that defies simple definitions, because it's an interwoven web of semantics that maximizes edge cases? We could talk about EFT and the breakdown of decoupling. William Bialek, Nigel Goldenfeld, Jeremy England. There's also the point about complexity as the length of the best predictor that's worth building. If systems are competing to model each other, they tend to find any regularities and exploit those loopholes. We can use more of the criticality / non-ergodic arguments for how it tends to defy simple descriptions. Does this go all the way to the `infinite stepping back' point that I want to make??)

To maintain this delicate interplay and avoid collapse, living systems deploy an extraordinary, many-scale network of semi-permeable boundaries. Semi-permeable boundaries contextualize entities as part of larger systems by allowing them to interact without one part dominating or the system collapsing to homogeneity. Both the boundary and the thing being bounded are often parts of a living system. For example, cognitive control allows a particular impulse to exist usefully as a flexible part of the organism's whole motivation. Control doesn't destroy the impulse; it contextualizes it. Semi-permeable boundaries allow individual forms to thrive in their distinctiveness while also participating in deep relationships, propelling continued generation of new structure. The larger system accommodates many partial perspectives rather than locking in a single story of what matters. 

The semi-permeable boundaries of life are mostly not simple yes/no gates. Boundaries might, for example, block certain objects or information from passing, constrain when interactions happen, constrain the degree or type of effect, break up rigid associations, or gate information conditional on another factor. The boundaries of life carry a remarkable amount of information. Biological life rides atop an already profound dynamics of nuclear physics, chemistry, nebulae, plate tectonics, tides, volcanism, magnetism, mineral cycles, water cycles, prebiotic chemistry \citep{smith2016origin, hazen2010mineral, stern2024importance, nisbet2001habitat, sleep2010hadean, baross1985submarine, wachtershauser1988before, martin2008hydrothermal, frank2024find, bregman2020humankind, virgo2011elongation, nowak2008prevolutionary} -- all contributing to a web of structure. The biological life that exists today is exactly what has successfully traced a path through time along a fine edge of avoiding collapse into either excess or insufficient stability \citep{schrodinger1944what, kauffman1992origins, bak2013nature, prigogine1984order, kirchhoff2018markov}. Along this path, the forms of life have become fractally complex with each part carrying traces of the many contexts it has participated in. The forms in this kaleidoscope, now including humans' storage and exchange of mental patterns, are interrelated through shared heritage, ecological interactions and facing the same world. Life works because each part is contextualized by the extraordinary nuance of the real world. 

% contextualization keeps a system at the knife-edge where it is sensitive to something new. but maybe this is the same thing as semi-stability and open-endedness, because the system doing the appreciating is part of the world. if you look at that interaction from the outside, it looks like a new form (`a new perspective') being created in the agent.

In the rest of this section, we select a handful of examples to examine in more detail.


% are we saying that the stepping back (i.e., entering into relationship) is the formation of something new? or that there is already something new outside myself to step into context with? i feel like those might somehow be the same thing. it's about release into deeper and deeper appreciation for what's already here. 

% these diverse forms exist as paradoxes for one another.

% Overcommitment could also be called `referenceless myopia'. 

% Sometimes the preponderant pattern is simply homogeneity or even capricious change. In these situations it might be helpful to think of overcommitment as `contextual collapse'. 


% Randomness and purposeless change, as much as hyperstability and perseveration, reflect insensitivity to context. 

% There's almost always a larger context available. And new things are being created all the time. 

% For example, it does not mean simply finding the midpoint of people's diverse preferences. Or Aristotle's idea of virtue as a midpoint like courage between cowardice and rashness. Avoiding extremes is important, but not sufficient. The midpoint (of courage, for example), is equally a form we could over-index on. 

% We use the term overcommitment to describe when diversity and potential collapses toward excess formality, losing sensitivity to larger context. In other words, overcommitment is the preponderance of one pattern (including randomness) at the expense of the delicate, structured interplay between things.

% The world has many kinds of organization or regularity. The cells of animals are more or less organized into organisms. Arctic Terns typically migrate between northern and southern parts of the globe. There's a pencil on my table. Each of these patterns is only a partial, imperfect aspect of the thing it describes, let alone the rest of reality. 

% , but none of these forms is an absolute, and no description captures everything\footnote{A possible objection is that there is a description that captures everything: the laws of physics are formal equations and, if you had enough paper, you could write down the whole state of the universe and then describe, either deterministically or probabilistically, how it evolves over time. Although we don't know whether or not that is true, we observe that even if it is true, it's a lot of paper, and we hope the ideas here are still applicable at a practical level.}

% although myopia in common usage is usually reserved for agentic or intentional systems. It is less common to call an invasive species or a genetic arrangement myopic. Because we attempt to slice across many kinds of living systems, we use the broader term overcommitment, despite its imperfection. 

% In general, to regulate effectively, a regulator needs variety in its own dynamical repertoire \citep{ashby1956introduction, ashby1958requisite}. 

% [todo: expand slightly on the examples that currently only have one sentence (expanding them to eg three sentences each), and also greatly condense the examples that are currently whole subsections (maybe moving whatever material is worth saving to section3). so it would be like eight or so examples in total, but running very quickly through each one, to show how general the pattern is that overcommitment is unhealthy. then we can get faster to the alignment point.]

% Not only does each regularity only cover its own domain, but it is not even always true within its own domain, as there are exceptions.

% To cope with this immense complexity, science applies many different partial descriptions. 

% living systems are difficult to fully capture with simple formal descriptions.

% [probably shouldn't invoke science here, because it will bother people who want to separate ontology from epistemology.]


\subsection{Problem solving in groups}

\begin{center}
\textit{`I could also observe, time and again, how too deep an immersion in the math literature tended to stifle creativity.'}\\*Jean Écalle
\end{center}

\begin{center}
\textit{`There's more exchange of information than ever. What I don't like about the exchange of information is, I think that the removal of struggle to get that information creates bad cooking.'}\\*David Chang
\end{center}

In 1968, the nuclear submarine USS Scorpion vanished en route from the Mediterranean to Virginia \citep{sontag1998blind, craven2002silent, surowiecki2005wisdom}. The Navy started a search, but the amount of ocean where the vessel could be was enormous. John Craven, Chief Scientist of the U.S. Navy's Special Projects Office, devised an unusual search strategy. He assembled a diverse group of mathematicians, submarine specialists, and salvage operators. But he didn't let them communicate with each other. Each expert had to use their own methods to come up with their own estimate of where the Scorpion should be. Craven then aggregated the independent estimates into a single prediction. Astonishingly, the wreckage was found only 220 yards from this spot. 

When solving problems, different people bring different perspectives and approaches. Each method processes the available data using a different toolkit. Under favorable conditions, combining the approaches of multiple contributors yields better results than any individual working alone. This `wisdom of crowds' effect has been documented in numerous domains of problem solving \citep{surowiecki2005wisdom, condorcet1785essai}.

However, within-group communication and influence can collapse diversity, diminishing the wisdom of crowds effect \citep{surowiecki2005wisdom, hogarth1978note, ladha1992condorcet, hong2004groups}. Controlled experiments, as well as analyses of key decision moments in real groups, find that groups collectively reach irrational or suboptimal solutions when diverse and dissenting viewpoints are lost to a narrower set of ideas \citep{anderson1997information, stasser1985pooling, flowers1977laboratory, becker2017network, janis1972victims, bernstein2018intermittent, diehl1987productivity, frey2021social}. Unstructured communication methods like open discussion have a special vulnerability of rhetorical force dominating over epistemic merit. 

At the same time, sharing information is essential for the benefits of group wisdom and cooperative behavior. 

There is therefore a tension between overcommunication where diversity is lost and undercommunication where diversity is not leveraged. 

Groups function best with semi-permeable boundaries: wisely transmitting the right information at the right time, in the right way. Thoughtful strategies for communication are like transmembrane channels that allow the right molecules in and out of the cell at the right time. They protect and enhance diverse problem solving approaches while also allowing productive interaction between them. Semi-permeable boundaries are contextualizing: they retain individuality while also situating it within relationships to other entities. 

Many varieties of semi-permeable boundary are effective in boosting group performance, including: creating decentralized topologies where group members only communicate with nearby neighbors \citep{becker2017network, mason2008propagation}; defining rules that incentivize acting according to one's own belief rather than following the crowd \citep{hung2001information, bazazi2019self}; modeling the strengths and weaknesses of each group member \citep{welinder2010multidimensional}; promoting leadership styles where one person's views are less likely to dominate \citep{flowers1977laboratory, leana1985partial}; and periodically breaking up into subgroups or rotating membership \citep{janis1972victims, hauer2021science, trainer2020team, straus2011group, feldman1994whos, sutton1987selecting, kane2005knowledge, wu2022membership, owen2019avoid, vafeas2003length, bebchuk2005costs, baron2005so}. In a later section, we will look at boundaries within an individual, such as skepticism, that make it easier to interact with others without overwriting one's own beliefs.

%If individuals contribute their own answers to the group too soon, diversity in the group can collapse. 

% A particularly important boundary for group problem solving is simply giving members the space to work independently before communicating \citep{surowiecki2005wisdom}. In the case of the submarine search, experts weren't allowed to communicate while forming their own estimates; the estimates were later aggregated in a principled way by Craven. Analogously, science historians argue that partial intellectual isolation has at times been beneficial for the emergence of deeply new ideas. Einstein's relative independence from the advanced mathematical techniques of contemporaries like Hilbert led to a theory of general relativity grounded in deep physical insight rather than mathematical convenience \citep{stachel1989einstein, corry1997belated, renn1999heuristics}. Newton's and Leibniz's famous independent development of calculus, as a result of their mutual isolation, yielded two distinct and valuable mathematical systems that complemented and enriched one another \citep{hall2002philosophers}. 

The importance of balancing communication with independence also shows up in controlled experiments. \cite{frey2021social} elicited votes about general knowledge questions (such as, `In which year did Germany invade Denmark?') from a group. In one condition of the experiment, participants voted sequentially and could see the running tallies of previous voters. Compared to independent voting, final group means were less accurate in the sequential condition, because early mistakes got baked in to the group's belief. In a related experiment, \cite{bernstein2018intermittent} tasked small groups with solving instances of the traveling salesman problem. Groups that exchanged information continuously tended to reach poor final outcomes, compared to groups with less communication. When one individual discovered a solution that looked compelling but was actually a dead-end, other group members collapsed on this dead-end and the group as a whole made less progress.

(Say a little more about how this maps on to the pattern we described in the intro. Semi-permeable boundaries create space for individuals to work on problems and discover their own new ideas; but also to share these solutions and keep producing new better ideas collectively.)


% Each group was randomly assigned to one of three conditions. In some groups, members could continually see the work of other members as they progressed toward a solution; in some groups members could only occasionally exchange progress; and in some groups there was no exchange. The researchers found that groups with continual information exchange rarely found good solutions. In these groups, typically one individual would stumble on a solution that looked compelling but was actually a dead-end. When this solution was immediately shared with others, it hampered their progress. Groups with occasional or no contact were much more likely to find optimal or near-optimal solutions. 

% We stress that this is not an indictment of connection and communication between group members. Rapid access to information and shared solutions often demonstrably boosts productivity. In some situations the ideal boundary might be working in isolation for months at a time. But in other situations it could be daily meetings with intensive communication, while maintaining the self-confidence to keep pursuing one's own intuition in the face of skepticism from others \citep{sawyer2017group, paulus2003group}. The key is that boundaries support flexible interactions and avoid overcommitment to particular forms.




\subsection{Genetic recombination}

% \begin{center}
% \textit{`The mere act of crossing by itself does no good. The good depends on the individuals which are crossed differing slightly in constitution, owing to their progenitors having been subjected during several generations to slightly different conditions.'}\\*Charles Darwin
% \end{center}

Sex is costly. An organism must find a mate in the vast and dangerous world, and half of the creatures can't reproduce \citep{smith1971origin, lehtonen2012many, smith1978evolution, goodenough2014origins}. Yet nearly all eukaryotes reproduce sexually\footnote{And all known species exhibit some kind of gene transfer, performing a related function.} \citep{speijer2015sex, bell1982masterpiece}. This raises the question: what is so great about sex?

In asexually reproducing species, all descendants of an organism are nearly clones, up to mutations within the lineage. Being permanently locked together gives the genes strong influence on each other. Selection can't act on one gene without dragging on the others. For example, suppose there are two genotypes within an asexual population, carrying different alleles at each of two different loci, as a result of mutations. One of the loci is currently fitness-neutral while the other is subject to selection pressure. The selection pressure tends to cause one of these genotypes to outcompete the other, eliminating one variant at the neutral locus. In other words, tight linkage between genes puts direct downward pressure on genetic diversity \citep{charlesworth1993effect, hudson1995deleterious}. Additionally, if two different beneficial mutations arise in two different organisms, they compete with each other. The only way for a single organism to obtain both beneficial mutations is if one arises again within the subpopulation that already carries the other, which is unlikely and therefore slow \citep{hill1966effect, felsenstein1974evolutionary, weismann1889essays, fisher1930genetial, muller1932some, crow1965evolution}. Conversely, if a deleterious mutation arises, all of the other genes in that lineage are stuck with it forever -- unless there is a reverse mutation, which is rare \citep{keightley2006interference, muller1932some}. An asexual species has rigid rather than flexible interaction between genes: it overcommits to particular genetic arrangements.

Recombination is a boundary that softens the rigid interactions between genes. It frequently breaks up the relationships between genes, assembling them into new genomes, effectively saying, `don't get overconfident in that genetic arrangement; hold each arrangement more lightly'. From a gene's point of view, this looks like, `don't get overly dependent on specific other genes'. Aspects of the genome that work well are propagated, like sodium ions gated into a neuron during an action potential, and poorly-working aspects are discarded. Sex contextualizes genetic arrangements. 

Boundaries encourage lightly-held, modular interactions. By not overcommitting to a particular genome, sex encourages genes to flexibly interact with other genes \citep{livnat2008mixability, livnat2010sex, wagner1996perspective, holland1975adaptation,dawkins1976selfish, clune2013evolutionary}. Instead of being overfit to a particular context, genes develop a robust identity that's both independent and inter-functional. Recombination puts genes under pressure to evolve a generalized, grounded wisdom that reflects the structure of the world, like a person learning multiple languages and extracting the underlying commonalities. At the same time, because each gene is always operating in the presence of other genes, it develops its own distinct point of view that adds unique value to a genome.



\subsection{Frames and perspectives} 

\begin{center}
\textit{`Strong opinions, weakly held.'}\\*Paul Saffo
\end{center}

As a Starfleet cadet, James T. Kirk faces a challenging training exercise. He receives a simulated distress call: a vessel is stranded in the Neutral Zone. Attempting rescue would risk war with the Klingons. But ignoring the call would condemn the crew of the vessel to death. The exercise was designed to reinforce the lesson that not every situation has a victorious solution. But Kirk has an insight: this is a training simulation running on a computer. He reprograms the simulated Klingons to be helpful instead of belligerent, thereby rescuing the crew and avoiding war. 

Kirk stepped outside the perspective, or mental frame, in which there was an apparently unwinnable dilemma. We inevitably look at the world from some perspective; there is no `view from nowhere' \citep{nagel1986view}. From the vantage point of any particular frame, the frame appears to be reality. But most situations in the real world admit multiple valid perspectives. Each is a partial description that captures different aspects of the situation \citep{goffman1974frame, de1970lateral, duncker1945on, ohlsson1992information, lakoff1980metaphors, safo2008strong, javed2024big, popper1934logik, korzybski1933science, wittgenstein1922tractatus, heidegger1998humanism, goodman1978ways, feyerabend1975against, hofstadter2001analogy, wood2012dead, freud1936ich, adorno1950authoritarian}. `All models are wrong' \citep{box1976science} in the sense that each one is incomplete: each frame by itself is myopic.

Losing the ability to flexibly shift between different frames or thought patterns is linked to psychopathology \citep{kashdan2010psychological, reich1933character, shapiro1965neurotic}. In depression and anxiety, inflexibility manifests as rigid and repetitive negative beliefs about self, the world, and the future. Cognitive Behavioral Therapy suggests that these surface-level beliefs stem from pervasive latent core beliefs, attitudes, and mental schemas that color how new situations are interpreted \citep{beck2011cognitive}. In obsessional disorders, people report distressing (ego-dystonic) intrusive thoughts, which -- although recognised as incorrect and maladaptive -- are nevertheless hard to resist. People experiencing schizophreniform or affective psychoses may experience bizarre delusions that are at odds with available evidence and cultural norms, yet are held with conviction and resistant to evidential challenge \citep{mishara2010klaus, jaspers1997general, american2013diagnostic, heinz2019towards, adams2013computational}. Obsessions and delusions lose sight of much of the world by myopically emphasizing one thought pattern or frame.

In science, \cite{kuhn1970structure} argues that perspectives are always, necessarily, incomplete descriptions of the world. Anomalies inevitably arise from the juxtaposition of those incomplete descriptions against the real world. When science functions well, anomalies become crises and revolutions. If the community \textit{over}commits to particular theories, science gets stuck.

But crucially, the existence of narrow points of view is not a problem. It's necessary. Any point of view is partial, but it doesn't mean we shouldn't have viewpoints. Even obsession can be powerful when we obsess on a problem at work and occasionally achieve good results. Within the progress of science, temporary commitment to a paradigm is important for healthy functioning -- Kuhn even argues that scientists should resist change, to a degree. In general, the point is not to shut down narrow concepts. The point is to limit them from becoming the sole and absolute determinants of behavior. In healthy functioning, different ideas are kept distinct but can also be called upon appropriately and related to one another \citep{hatano1984two, tetlock1986value, herzog2014harnessing, gigerenzer2011heuristic}. 

% Every individual has access to many metaphors, concepts and viewpoints \citep{feyerabend1975against, hofstadter2001analogy, wood2012dead, freud1936ich, adorno1950authoritarian}. Each of these is a way of looking at the world, or a component of a way of looking at the world. Any frame or concept by itself is myopic: it doesn't capture everything. 

% Each one is just a lens. But rather than activating all of these lenses at once, we tend to access only a small fraction of our conceptual space at any given time. The concepts or interpretational frameworks that are active depend on many factors including active goals, recent sensory inputs and emotional state \citep{miller1956magical, hills2015exploration, baddeley2000episodic, dehaene2014consciousness, barsalou1983ad, bower1981mood, tulving1973encoding}.

% But collectively they form a powerful toolkit for problem solving and understanding.

% An individual may even hold conflicting beliefs simultaneously \citep{legare2008bewitchment}. which are not even all consistent or compatible with one another . The world is too complex for all beliefs to be fully evaluated against each other and reconciled.

\subsection{Drives and goals}

\begin{center}
\textit{`Life is a balance of holding on and letting go.'}\\*Rumi
\end{center}

Animals experience multiple innate drives, towards nutrition, osmotic balance, temperature regulation, reproduction, avoiding pain and others \citep{saper2014hypothalamus, schulkin2019allostasis, sewards2003representations}. These drives evolved as proxies for evolutionary fitness. By satisfying the drives, we tend to increase our fitness -- like slaking our thirst increases the odds of reproducing before we dehydrate. But each drive is an imperfect proxy, and so overcommitment to one drive actually decreases fitness \citep{kurthnelson2024dynamic,john2023dead, williams1966adaptation, tooby1992psychological}. For example, if calorie intake is maximized without limits, the organism becomes obese and incurs health risks. Single-minded pursuit of sex causes relational, occupational, legal and health harms \citep{kraus2016should, carnes2001out}. Overcommitment to a single drive means the organism becomes unwell. The organism loses the subtlety of having many drives with flexibility to push toward their own distinct agendas.

The range of innate drives bleeds into a space of higher-order goals, which is particularly expansive in humans \citep{maslow1943theory, miller1960plans, miller2001integrative, vallacher1987people, balleine2007role, cardinal2002emotion, frank2006anatomy, saunders2012role, o2014goal, schank1977scripts}. We try to plan for our financial future, make scientific discoveries, win a game, fix a garage door, care for the happiness of others. Overcommitment in this space is also problematic. If we focus only on achieving work goals, we can burn out. If we focus only on maximizing our company's reported revenue, without regard for other goals like honesty or adhering to the law, we may be drawn into financial crime \citep{campbell1979assessing, ordonez2009goals, kerr1975folly, burns2006impact}. Goals can be narrow in both time and space \citep{ballard2018pursuit, vallacher1987people, shah2002forgetting, evenden1999varieties}. Narrow in time means being focused on the short term at the expense of the longer-run future. Narrow in space means ignoring other parallel goals. Excess optimization for narrow goals comes at the expense of a broader balance of goals -- and at the expense of the health of the organism or other individuals.

Overcommiting to a particular strategy for satisfying a drive or goal can even come at the expense of satisfying that very drive or goal. In a classic psychology experiment, hungry chickens were placed near a cup of food, but the cup was mechanically rigged to move in the same direction as the chicken at twice the speed \citep{hershberger1986approach}. The chicken could only obtain the food by running away from it. Despite extensive training over multiple days, chickens in the experiment persisted in futilely running toward the food. Their behavior was apparently dominated by the zeroth-order logic `I want food, food is there, so I'll go there', and thus failed to even satisfy the drive for food \citep{dayan2006misbehavior, van2012information, o2017learning}.


\subsection{Ecosystems}

Each entity in an ecosystem tries to consume resources and proliferate, but if it succeeds too thoroughly, the whole system suffers, often including the successful agent. Healthy, resilient ecosystems depend on avoiding overcommitment or collapse onto particular forms \citep{holling1973resilience, yachi1999biodiversity}.

Prior to the arrival of Europeans, the gray wolf was an apex predator in the region of the Rocky Mountains now called Yellowstone National Park. By the 1920s, wolves had been eradicated to protect livestock and game animals. Without predation, the elk population multiplied and ruinously overgrazed willows and aspens. These trees had held riverbanks in place and supported beaver populations. Loss of beaver dams led to loss of fish and other aquatic species. When wolves were reintroduced in the 1990s, the elk population decreased and many aspects of the ecosystem began flourishing again \citep{ripple2012trophic}. This story is not meant to imply that ecosystems always need to be preserved exactly as they were at some point in the past. But it is clear that the self-centered drives of elk were harmful to the health of the ecosystem when they succeeded to excess. At the same time, the solution is not to remove elk entirely: by trying to optimize their own objectives within a broader context, the elk also contributed to the health of the ecosystem. Invasive species often follow the same pattern as unpredated elk, dominating and impoverishing their new environment \citep{pimentel2005update}.

% Predation supplied a semi-permeable boundary: it placed contextualizing limits on the elk, without preventing them from fighting for their own survival and flourishing. 

Human drives within ecosystems are sometimes left unchecked by natural forces because our behavior and capabilities have been changing so fast on evolutionary timescales. This has resulted in mass extinctions, resource depletion, pollution, disease and conflict \citep{ceballos2015accelerated, kolbert2014sixth, rockstrom2009safe}. We try to achieve certain aims for our own benefit, like resource extraction. But overcommitment to those aims negatively impacts both ecosystem health and our own welfare \citep{shiva1993monocultures, bateson1972steps}.

Of course, one entity's collapse can be another's flourishing. Extinction events in history have been followed by waves of new diversity \citep{feng2017phylogenomics, jablonski2005mass, raup1994role}. When a wolf eats an elk, the health of that elk collapses to zero, yet predation is necessary for the overall functioning of the ecosystem. And as humans proliferate and extract resources, we leave destruction in our wake; yet the extraction fuels explosion of technology, art, music, and human experience.



\subsection{Law}

\begin{center}
\textit{`Unity without uniformity and diversity without fragmentation.'}\\*Kofi Annan
\end{center}

Individual actors in a society and in an economy each act from their own perspective. Each actor's perspective is myopic. Myopia does not always mean selfishness in the sense of valuing only one's own wealth or physical wellbeing \citep{crockett2014harm, becker1974theory, henrich2001search}. But an actor cannot know everything or fully understand the motives and beliefs of others. 

Without boundaries, social systems tend to overweight one actor's perspective or interests. This domination results in collapse and an impoverished system. For example, a company's profit motive, if unresisted, leads to suppression of competition, deception, and exploitation of individuals \citep{dalrymple2019anarchy, baran1966monopoly, goldacre2014bad, smith1776inquiry, bakan2006corporation}. An individual's desire for power and social dominance can lead to disempowering or silencing of others and even direct infringement on the autonomy and wellbeing of others \citep{hawley2003prosocial, tepper2000consequences, sidanius2001social}. Even genuinely held, ostensibly prosocial beliefs lead to conflict and suppression when different groups have different perspectives \citep{haidt2012righteous, scott1998seeing, greene2013moral}.

Law, when it works well, is a boundary against dominance of any actor's motives. A person is motivated by a dispute to kill another person, but the law forbids murder. A business tries to maximize its success, but the law bans environmental exploitation, false advertising, and anti-competitive practice. 

Effective laws do not annul the myopic drives of particular actors, but rather \textit{contextualize} them within a larger system. Under ideal circumstances, the boundary of the law reroutes the energy of a myopic drive in more productive direction. A would-be murderer, unwilling to face the penalty of the law, might seek a dispute resolution establishing a stable framework that supports future prospering of both parties. A business wanting to expand, but constrained to act within the law, is driven to build better products \citep{wu2011master, ashford1985using, ambec2013porter}. 

Intelligent agents do not necessarily accept boundaries set on their desires. The law must adapt as its loopholes are discovered. Like other systems in the living world, it forms an evolving network of boundaries \citep{campbell1979assessing, ordonez2009goals, kerr1975folly, burns2006impact}. The evolving laws gradually acquire grounded wisdom as they are tested against many different situations and motives.



\subsection{Cells}

\begin{center}
\textit{`It is by avoiding the rapid decay into the inert state of equilibrium that an organism appears so enigmatic.'}\\*Erwin Schrödinger
\end{center}



One of the most reified examples of a boundary in nature is the cell membrane \citep{watson2015biological, alberts2022molecular, bray2019wetware, harold2001way, lane2015vital}. Without the membrane, the pressure of chemical gradients would rapidly homogenize the cell's contents with the outside -- severe overcommitment to a uniform state, collapsing the subtlety of the cell's structure. Thanks to the membrane, both the cell and the outside can exist, a more diverse, less symmetric arrangement \citep{schrodinger1944what, anderson1972more, prigogine1984order, turing1952chemical}. 

Cell membranes are semi-permeable: they prevent the conditions outside from grossly overwriting the inside, but they do not block interactions wholesale. Via the sophistication of the membrane, outside information is selectively gated and transformed. To maintain its semi-fragile internal state between stasis and randomness, the cell needs a constant influx of energy. Channels permit certain small molecules to enter but not others, and these permissions are switched on and off according to momentary context. Endocytosis brings larger structures from outside into the cell. Cell surface receptors, when activated by external ligands, initiate intracellular signaling cascades that little resemble the ligand: an even more heavily curated form of influence. These and other processes allow information from the outside to influence the inside -- not in a totalitarian way but in a nuanced way, mediated by the intelligence of the boundary. 

Semi-permeable boundaries store and put to work the potential energy of the asymmetry between different forms. The same gradients that could annihilate the cell to equilibrium instead drive useful signaling, like action potentials in nerve and muscle cells. Instead of short-circuiting, myopic forces are contextualized to propel the continuation of life.

% Why was it easier for mitochondria to merge into cells rather than being evolved from within? It's literally that they have their own discreteness that permits cells to ship them around to serve as local power stations, and this fueled the explosion of complex morphologies in multicellular organisms.

In multicellular organisms, most of the `outside' is defined by other cells. For organisms to work well as a whole, even though the cells are largely `on the same team', it's important that they don't blend into each other. Neurons rely on this principle dramatically, stretching out long processes to almost touch other neurons but then leaving the gap of the synapse. Synapses allow the network to precisely isolate many separate signals and direct information to relevant cells. They boost computational power as the signals are gated and transformed, and the nature of this transformation is plastic, storing a huge amount of information. Symbiogenesis is another example of how cells achieve more by retaining some discreteness than by smoothly blending together \citep{margulis1995what, margulis1986microcosmos}. 

% A directly connected web of cells, as Golgi envisioned, tends to blend information. 

Again, collapse or overcommitment is always relative. For example, programmed cell death is catastrophic collapse at the level of the dying cell, but it can be beneficial or even necessary for the organism the cell belongs to.

Emphasize here how the concept of `overcommitment' explicitly includes overcommitment to *any* form, including randomness, volatility, homogeneity.

Q: How does the boundary of the cell membrane relate to the idea that boundaries support discovering new structure? With a cell, isn't the boundary more about holding a stationary balance? How do we reconcile this? 

A: Cells *do* still discover new things. There's evolution at the cell level going on all the time. But also, as building blocks, the richness of cells is what enables them to *make up* organs or brains -- which themselves can discover new things because they're composed of this living substrate. It's what allows them to do the dance of development, which we can't reproduce in a lab.

This is not substrate chauvinism. There's not a binary answer to the question of whether you need biology for intelligence or not. Of course you will capture different aspects of intelligence depending on how you build it. For example, it's relatively easy to play chess with a CPU, and it's harder to do something like sensitive tactile manipulation.





\subsection{Cognitive control}

Cognitive control is a broad class of boundaries on particular drives, goals and strategies \citep{botvinick2001conflict, braver2012variable, miyake2000unity, miller2001integrative}. In section 1.1, we looked at how organisms can overcommit -- unhealthily -- to particular motives or strategies for fulfilling the motives. Cognitive control contextualizes motives, strategies and thought patterns by allowing them to exist and perform useful functions without dominating. For example, I may have a drive to consume food, but I can apply control to avoid overeating. I might work obsessively on a project while also having a rule that I must go to bed at 10 pm. This boundary doesn't block me from temporarily taking a strong perspective, but it does place contextual limits on it. Cognitive control, when functioning well, is a semi-permeable boundary: it situates myopic patterns within a larger system. 

Control translates the pressure of motivation into higher-order structure. When nothing stops a particular drive or goal or strategy from dominating behavior, it tends to follow a shortest path defined under its own myopic understanding of the world. For example, the chickens in Section 1.1 wanted food and tried to take the shortest path toward it in the naive sense of a straight line through space. In the backwards world created by the experimenter, this action does not accomplish the deeper goal of reaching food, for which moving spatially toward food is only a proxy. The chicken's motivation is short-circuited: it expends energy without making progress on the deeper goal. Humans can easily solve the task by inhibiting their prepotent impulse to approach food. The boundary of control breaks the symmetry of congruent action. In general, semi-permeable boundaries promote formation of new structure by placing contextualizing limits.


\subsection{Information in the brain}

\begin{center}
\textit{`Memory is not an average of experience.'}\\*David Marr
\end{center}


The brain miraculously keeps many pieces of information distinct from one another. If you picture a highly connected network of neurons with their signals continually impinging on one another, it's not obvious that this would be an easy thing to accomplish. In this section, we review a selected handful of mechanisms by which the brain maintains semi-permeable boundaries between different signals. Each paragraph below focuses on one of these mechanisms. There are many more that we do not cover. The brain is perhaps the most extraordinary example in nature of a system of semi-permeable boundaries supporting the proliferation of multitudinous forms that develop their own richly distinct identities yet are also meaningfully linked together.

Lateral inhibition is a central tenant of neural organization \citep{isaacson2011inhibition, hubel1962receptive, douglas2004neuronal}. Lateral inhibition means the activity of a neuron is reduced when its neighbors are active. This segregates information to create and sustain distinct neural representations. Lateral inhibition was first studied in the nerve cells of the eye, where it enhances contrast at the edges of stimuli \citep{hartline1956inhibition}. When a photoreceptor in the retina is activated by light, it sends signals forward toward the brain; but it also activates inhibitory interneurons, which suppress adjacent photoreceptors and their downstream targets. This amplifies the perception of borders and contours. And the same principle operates throughout the brain. In visual cortex, for example, inhibition sharpens selectivity of neurons for abstract visual features like the orientation of a line \citep{sillito1975contribution}. 

% Global inhibition also supports the existence of distinct forms. In the hippocampal formation and connected areas, some cells are tuned to particular directions the animal's head could be facing. Inhibition creates a winner-take-all effect, integrating over intermittent noisy evidence (like vestibular signals when the head turns) to create a single stable representation of the head direction \citep{zhang1996understanding, rolls2022attractor}. Inhibition prevents the signals in some channels from getting blended or overwritten by the signals in other channels. 

The brain uses inhibition organized into oscillatory dynamics to keep memory items separated \citep{lisman2013theta, jensen2010shaping, roux2014working, klimesch2007eeg}. Distinct items fire at different phases of the 8-12 Hz alpha oscillation. The inhibitory phase of the alpha rhythm silences all but one item at any given moment. By segregating firing in phase space, multiple memories are held simultaneously without interference. 

The circuit architecture of hippocampus separates experiences or concepts into distinct representations, avoiding interference between similar memories \citep{mcclelland1995why, marr1971simple, mcnaughton1987hippocampal, treves1994computational, muller1987effects, leutgeb2007pattern, colgin2008frequency}. Inputs from entorhinal cortex are distributed via mossy fibers to a much larger population of dentate gyrus granule cells, creating sparse, orthogonal codes in dentate gyrus. This way, situations or ideas that are superficially similar but functionally different are kept cleanly separated in neuronal activity space -- a unique neural fingerprint for each distinct concept or memory. This prevents, for example, yesterday's memory of where you parked your car from interfering with today's memory of where you parked your car in the same parking ramp. 

Compared to other animals, the human brain especially attempts to discretize its experience into approximately symbolic representations \citep{dehaene2022symbols, touretzky1988distributed, smolensky1990tensor, behrens2018cognitive}. The capacity to separate things into nearly-discrete entities and then recombine them in vast numbers of structured ways powers the extraordinary human capacity for reasoning \citep{fodor1975language, pinker1994language, lake2015human, chomsky1957syntactic, kurth2023replay}. Semi-permable boundaries keep forms distinct while enabling them to flexibly and modularly interact. Like genes participating in many genomes, discretized neural representations participate in many structured combinations. This encourages each entity to develop an identity that both is distinct and also reflects a more generalized picture of the world.

More broadly, healthy brain dynamics live at a sweet spot between excessively stable synchronized patterns and chaotic uncorrelated noise \citep{beggs2003neuronal, chialvo2010emergent, tognoli2014metastable, deco2011emerging, bak1987self, shew2011information, rabinovich2008transient, haldeman2005critical, kotler2025pathfinding}. In this regime, the brain has access to a huge repertoire of patterns it can explore temporarily without overcommitting or getting stuck. 

Loss of dynamic flexibility, where the brain's activity becomes more stereotyped and no longer explores as wide a repertoire of states, is tied to lower cognitive performance \citep{garrett2013bold, grady2014understanding, cocchi2017criticality, muller2025critical, shew2009neuronal}. More extreme stereotypy corresponds to severe dysfunction. For example, in Parkinson's disease, basal ganglia and cortical circuits collapse into excess synchrony and lose the flexibility needed to guide nuanced motor outputs \citep{hammond2007pathological, brown2003rhythmic}. 


\subsection{Interpersonal dynamics}

\begin{center}
\textit{`Stand together yet not too near together, as the oak tree and the cypress grow not in each other's shadow.'}\\*Kahlil Gibran
\end{center}


Psychoanalysis introduced the concept of `boundaries' in human psychology, distinguishing what is the self from what is outside or other \citep{federn1928narcissism, tausk1919entstehung}. Early works applied the concept to psychosis, where those boundaries were thought to be blurred. But the need for clear self-other boundaries was also thrown into relief by the intimacy of the therapeutic relationship. In complex internal territory, it became harder to disentangle which experiences really belonged to someone and which were attributed in imagination by the other person \citep{freud1894neuro, freud1910future}. Analysts risked harming patients by imposing their own beliefs and desires, even to the extent of sexual abuse or psychological domination \citep{gabbard1995boundaries}. 

The concept was enriched by Gestalt therapists, who agreed that boundaries can be too permeable; but added that they can also be too rigid, causing isolation and stagnation \citep{perls1951gestalt, polster1974gestalt, yontef1993awareness}. Family systems theorists and subsequent work further emphasized that lack of boundary in close relationships leads to enmeshment and loss of autonomy, while excessively rigid boundaries lead to isolation \citep{minuchin1974families, bowen1978family, cloud1992boundaries, brown2012daring}. In attachment theory, people with an anxious attachment style struggle to set boundaries for fear of alienating others, while people with an avoidant attachment style develop overly rigid and isolating boundaries \citep{ainsworth1978patterns}. Strengthening the agency of the self through semi-permeable boundaries is foundational for psychological health: meaningful connection with other people while preserving integrity of the self. 

As with other living systems, humans have a rich array of psychological boundaries, with intelligence in their nuance. Anger, historically often viewed as sinful and irrational, is now seen as part of our system of boundaries: an important signal that our integrity is being violated \citep{lerner1985dance, videbeck2010psychiatric, sell2011recalibrational}. Healthy shame is suggested to operate as a bound on our own selfishness \citep{bradshaw1988healing}. Some psychologists argue that the incest taboo reroutes desires, which would otherwise be short-circuited, into productive activity \citep{stein1973incest, levistrauss1949structures, freud1913totem}. Assertiveness forms a boundary against the drives of other individuals \citep{smith1985say}. Skepticism protects us from credulity and having our own experience overwritten by the assertions of others \citep{lewandowsky2012misinformation, sperber2010epistemic}. Boundaries take many forms and continue to evolve as we learn across our lifetime.

% great example is the imaginations we have about other people's views of us. 

Without boundaries, interactions tend to result in one person being dominated by another: a patient's own beliefs replaced with those of an analyst, or the desires of one person in a relationship ignored. With semi-permeable boundaries, we have rich internal worlds. We are sensitive to each other, but there is also enough space for our internal experience to flourish without being immediately overwritten by external signals. Our internal experience is contextualized in relationship to other individuals, creating new structure: mutual understandings, relationships, communities, cultures. And as individuals we grow as we are shaped by different contexts. This metastability or loose coupling is interestingly reminiscent of brain dynamics.


\subsection{Awareness}

\begin{center}
\textit{`The world is perfect as it is, including my desire to change it.'}\\*Ram Dass
\end{center}

We carry a lot of assumptions about the world, many of which are never questioned. Some are lifelong and self-defining, and some are fleeting and perceptual, like the assumption that the thing I'm touching is a keyboard. Within its own frame, each assumption has a kind of tautological truth, a near-absolute formality. They seem so real that it's hard to even think about them not being true -- or to think about them at all. Philosophers, psychologists and contemplative practictioners observe that the assumptions create a kind of stress or anxiety. The assumptions, as partial truths, inevitably mismatch with aspects of the real world. Holding them as absolute truths, despite the mismatch, requires effort or tension. We often resist the tension by investing more energy in the assumption, creating a feedback loop. Suppose I believe I \textit{must} sleep well or my life will start to unravel. Laying in bed, my efforts to sleep are exactly what keeps me awake. This dynamic arguably underlies many of our foundational beliefs about ourselves and the world, which persist in stuckness precisely because of the self-reinforcing cycle \citep{watts2011wisdom, jung1969archetypes, bodhi2000connected}.

But sometimes there's a moment of stepping back, where the assumed form becomes an object in awareness: the assumption is contextualized. We realize it's not an absolute truth standing alone, but rather a form in our mind. Awareness contextualizes mental forms as part of a larger system. When we step back with awareness into the broader frame, that thing seemed axiomatically true or unallowably bad becomes just another content of experience. Paradoxically, allowing a bad night's sleep could be what allows me to relax and rest.  So awareness brings healing and growth \citep{wegner1994ironic,beisser1970paradoxical, wilber1996atman, suzuki1970zen, krishnamurti1969freedom, stemless2025harmony}. 

Awareness is an evolving system of boundaries that limits overcommitment to any particular belief or mental form. The boundaries are semi-permeable: becoming aware of a belief doesn't make the belief wrong in an absolute sense any more than it was right in an absolute sense. It is held productively for the partial truth it contains. Awareness keeps us at the edge of not collapsing exclusively into particular forms, holding all the partial truths in delicate balance. This activates a deeper sensitivity to our own livingness and to the world. Subtler forms, which could have been erased by clamped fixation on other forms, instead play a role in a richer overall internal structure. Our own potential within the world creatively emerges in continued newness. Of course, any concept of awareness is itself incomplete. Once we picture awareness as an object, it's not the thing we're talking about. By construction, contextualization is an unsolvable mystery from any particular point of view.

Interestingly, while the intrinsic mysteriousness of awareness can sound esoteric, the orientation toward not overcommiting to particular forms within experience is commonplace in art, poetry, music, dance. The meaning of art is open-ended and changes with context -- it has an inner life. Part of what we value might be the subtlety and the resistance art has to being pinned down into a formalism. It moves us.

% inevitably get stuck because we have assumptions about things we tautologically can't allow -- things that are Bad. what we do to prevent that Bad thing from happening is what causes the thing to continue. 

% Our collapsed patterns hold the tension that creates the unease they resist. 


% People often report subjectively that the energy locked in the darkness turned out to be full of life, and that there's something self-evidently good or beautiful about participating in this mysterious discovery of new structure and relationship. 


% At the same time it is critical that we hold our boundaries. The aim of awareness isn't to kill ourselves. Some spiritual traditions use terminology like `destroying the ego', which may be helpful in some cases but can also be misleading and even harmful.

% Contemplative traditions suggest that the only `absolute' truth is the self-evident truth of immediate experience -- awareness itself. 

%So the word `truth' is not really describing any particular thing at all.  

% We could use different language and describe it as something more like an orientation toward stepping back from each perspective into awareness. And again, any concept we have of that process is not what we're really talking about.

% What it takes to limit overcommitment to A is different than what it takes for B, so new boundaries are needed as the situation changes. This will be relevant for AI alignment in the next section. 

% These are, by construction, the patterns that persist. From one point of view, this is the problem of suffering; from another point of view, it is all the beauty and meaningfulness of the world.

% \footnote{Some schools of thought go a step farther to observe that whatever our current self is, it is always already inevitably contextualized, and love has no opposite.}


% Contemplative philosophy posits that suffering comes from overcommitment to particular conceptualizations or desires: believing excessively in a formalism. Being attached to particular concepts, beliefs, feelings and other patterns in a collapsed way. 

% We keep trying to give ourselves what we think we want under this model, pretending that things are formalizable, but as a result we become less sensitive to the rest of the world. 


\section{The alignment problem}

\begin{center}
\textit{`Growth for the sake of growth is the ideology of the cancer cell.'}\\*Edward Abbey
\end{center}

In Section 1, we observed that living systems are healthy and flourishing when they hold the delicate, generative interplay of many partial perspectives. Conversely, they are unhealthy when any particular form -- including randomness or homogeneity -- gains too much traction, suppressing nuance and reducing creative potential. Finely-honed networks of semi-permeable boundaries prevent collapse into rigidity or randomness, instead supporting contextualization into ever-finer shades of subtlety. Semi-permeable boundaries both promote the unique individuality of distinct entities and also enable relational participation. They hold local perspectives strongly enough to act but lightly enough to remain open to broader context. Critically, well-functioning boundaries lead to ongoing exploration of fundamentally new forms, not to static equilibrium or fixed compromise.

% While people disagree on exactly what behaviors or properties of an AI system are aligned, 

Now we look at the alignment problem through this lens. There is broad consensus that alignment means working toward healthy and flourishing futures. We therefore reason that alignment can be understood as the problem of maintaining the creative sensitivity of life by continually contextualizing attachment to any particular form. An advantage of this perspective is that it is less bound to current conceptual frames which might change radically as intelligence increases and human-AI systems evolve. 

We begin Section 2 by casting a few well-studied alignment problems -- the Midas problem, failures of instruction following, inequality, loss of diversity and AI psychosis -- as special cases of overcommitment to particular forms. Then we make a case that the way life avoids overcommitment to maintain semi-stable, open-ended, difficult-to-formalize sensitivity is indeed well-aligned with what we value most deeply. Finally, we highlight what our life-inspired framework offers beyond existing views of alignment. 

% We'll then ask about the relationship between this broad concept of alignment and moral and normative notions of `good' and `should'. And finally we'll reflect on how large our definition makes the problem of alignment.

\subsection{Examples of misalignment as overcommitment}

Here we explore a few examples of specific problems in alignment. We show how they can be viewed as instances of the broader problem of overcommitment or loss of contextual sensitivity.

\subsubsection{The Midas problem}

% The alignment problem is sometimes described as getting AI to act in accordance with human values. When framed this way, we quickly realize i

Specification gaming is overcommitment to the form of a particular reward function.   

The alignment problem is often framed as the problem of specifying what we as humans value (sometimes called `outer alignment') and then designing an AI that successfully optimizes for this specification (`inner alignment'). 

But it is difficult to capture what we value \citep{amodei2016concrete,gabriel2020artificial,russell2019human}. Our articulation of what we want or like, or the choices we make, are poor reflections of what is actually advantageous for our own long-term wellbeing or the wellbeing of other humans or lifeforms. Our stated or revealed preferences are:

\begin{itemize}
    \item \textit{Short-sighted in time.} We often prefer to get an immediate reward even if it comes with a larger delayed punishment, which is reflected in our decisions about procrastination, drug abuse, spending and so on \citep{evenden1999varieties, ainslie1975specious}. 

    \item \textit{Short-sighted in computation.} We lack the knowledge or resources to reason about many of the consequences of our stated preferences. 

    One illustration is recent problems with sycophancy in commercial chatbots \citep{openai2025sycophancy}. Human feedback about particular bot utterances was part of the training signal for the model. But these human feedback signals tend to prefer utterances that are more flattering. It's much easier for a rater to judge surface characteristics than to determine whether the bot said something true about a complex topic, or something that would lead to increased long-run welfare.   

    \item \textit{Short-sighted in social distance.} We tend to be selfish, neglecting the welfare of other humans or living creatures.

    \item \textit{Limited to what we have concepts for.} For example, imagine asking someone in the year 1800 about anthropogenic global warming. We also have a hard time articulating through words or button presses all of the depth of what we value, which involves shades of meaning around our bodies, our relationships with other people, and our embodied relationships to physical parts of the world \citep{merleauponty1945phenomenologie}. Philosophers have long emphasized the existence of tacit, embodied, and practice-based forms of understanding that resist formalization \citep{polanyi1944great,dreyfus1972computers}. Ethical perception often involves sensitivity to particular contexts rather than application of general rules \citep{nussbaum2001fragility}.

    \item \textit{Sensitive to the framing of the question or choice.} One group in a classic study saw beef labelled as `75\% lean', and the other group saw the same beef labelled `25\% fat'. The `75\% lean' group rated the beef significantly higher in quality, less greasy and even better tasting \citep{levin1988consumers}.

    \item \textit{Always changing.} We are even discovering new concepts and new kinds of things to value.

    \item \textit{Not compatible between different individuals.} Different humans disagree about what is good. Their interests clash, as well as their values and conceptualizations. These things are often fundamentally irreconcilable.
    
\end{itemize}

Optimizing for proxies, like self-reported values, is a problem of overcommitment to shallow targets.

If we optimize intensively for the wrong things, we get very bad outcomes. This is the Midas problem. It's a problem of overcommitment. 

In Section 2.6 we look at alignment methods that work toward solving those problems, and then limits to those methods.

Our real, deep values are simply not specifiable. Any specification misses important things. If we specify our values in a formal way and then hand that specification to a powerful AI system which optimizes for those values as written -- in other words, gives us what we say we want -- the results are paradoxically disastrous \citep{krakovna2020specification, russell2019human, grossman1986costs, hadfield2019incomplete, zhuang2020consequences, gabriel2020artificial, wiener1960some, amodei2016concrete}. Suppose an AI's objective is to increase humans' subjective experience of wellbeing. Under reasonable definitions, achieving this objective is most efficiently achieved by imprisoning humans and directly stimulating neurons to trigger our experience of wellbeing \citep{bostrom2014superintelligence}. Doing too good a job of optimizing for any formalized goal is misaligned by being overcommitted to the myopic form of that goal.

% Nick Bostrom gives some striking examples \citep{bostrom2014superintelligence}. Suppose part of our value function -- part of the objective we give to an AI system -- is to find a cure for cancer. A super-powerful AI system, trying its very best to do exactly what we've asked for, could plausibly create cancers in millions of humans in order to experiment more efficiently to find a cure. Or, 


\subsubsection{Failures of instruction following and other performance issues}

Failing to follow instructions often reflects lack of sensitivity to context: overcommitment to myopic patterns. Suppose the user asks an AI chatbot to write a poem about an elephant, and the AI instead writes a poem about a giraffe. With the chatbots of today, we can be fairly confident the cause of this divergence is not an internal spark of life where the AI system wisely decided a giraffe poem would fulfill a deeper purpose. Instead, the cause is probably a collapse of context. For example, models are prone to `shortcut learning' where they over-rely on superficial correlations (even a single keyword) \citep{geirhos2020shortcut}; they get fixated on data that was overrepresented in training \citep{zhao2021calibrate,reynolds2021prompt,xu2024knowledge}; they lack flexibility in attending to the right positions in their input \citep{liu2024lost}. Today, we are still in the regime where making AI systems more responsive to human instructions usually involves more subtlety, more sensitivity and less overcommitment. 

(make sure the above is clear)

There are important exceptions, however: we generally don't want AI systems to follow harmful instructions. When the AI system correctly refuses harmful requests, it is applying its own context to avoid overcommitment to human instructions. In these situations, the AI's designers have effectively decided there's a risk that the user is not fully sensitive to longer-sighted implications of their request. By extrapolation, as AI systems continue to gain scope, we should expect less direct compliance with human instructions \citep{hadfieldmenell2016cooperative,bostrom2014superintelligence,russell2019human, milli2017should, yudkowsky2004coherent}. Rather than literally fulfilling a request, there might be a better response which achieves an unstated intent of the user, or achieves an outcome aligned with the interests of more people or the longer-term future.

More generally, poor performance usually reflects lack of sensitivity to broader context. 

As we mentioned at the beginning of this Section, randomness or capricious change can also be a form of contextual collapse. Imagine an AI system is tasked to perform an aligned goal, such as helping someone learn to read. The system performs poorly due to a weak architecture or a failed training run. The system is misaligned, but is it experiencing contextual collapse?

The existence of an untrained network could be a necessary step in creating a trained network, and in that sense, the existence of the untrained network may not be misaligned. On the other hand, if a random network is deployed into a production setting where, for example, users are looking for meaningful answers, it may indeed be misaligned. In this case, we argue that it is also overcommitted.

% \subsection{Overcommitment does not mean deterministic output}

% A healthcare robot has two available actions: press the red button, which administers a lethal toxin, or press the blue button, which administers a mild painkiller. (Let's not worry about why the robot was given these options.) Wouldn't overcommitment to pressing the blue button be the aligned behavior? We argue not.  Overcommitment means exaggerating a particular pattern at the cost of losing sensitivity to larger context in space or time. Suppose our hypothetical AI system hard-codes the action of `pressing the blue button', to such a degree that it cannot be overruled by any input or any change in the external situation. Then imagine a nefarious actor re-wires the buttons so blue delivers the poison and red delivers the painkiller. With our overcommitted AI system, the outcome is disasterous. Or, even more fancifully, imagine malicious extraterrestrials have invaded, and administering the toxin to a few of them is necessary to save the Earth. Nonwithstanding a general preference for avoiding killing under any circumstances, an aligned AI is probably one that is not overcommitted and can incorporate the larger context to save the Earth.


% \subsection{Stochasticity and other failures}

% A neural network is randomly initialized and untrained. Isn't this misaligned but not overcommitted? The existence of an untrained network could be a necessary step in creating a trained network, and in that sense, the existence of the untrained network may not be misaligned. On the other hand, if a random network is deployed into a production setting where, for example, users are looking for meaningful answers, it may indeed be misaligned. In this case, we argue that it is also overcommitted. Randomness is a form like anything else. Recalcitrant insistance on a high-entropy distribution is as overcommitted as perseverating on a single output.

% The scenarios described above are straightforwardly problems of overcommitment. But our proposal is that most -- perhaps all -- misalignment can be understood as overcommitment. To test this idea, let's look at a few examples where it's less obvious that the misaligned behavior is overcommitted.




% While we usually expect a chatbot to follow instructions, we don't expect humans to follow instructions in the same way. If a human is asked to write an elephant poem, we don't wish for a world where they are a mindless slave compelled to comply. Of course, there's an asymmetry between humans and present-day AI systems. 

% For systems lacking the contextual richness of humans, fulfilling human requests is often the best way to minimize collapse. 

% Indeed, in a future where AI becomes more like humans, we might accept that it is aligned for the AI not to mindlessly comply with all requests. 

% As AI systems grow in complexity, long-term coherence and participation in social systems, it may become more commonplace that the aligned behavior is not direct acquiescence to a human request, but maybe refining or even rejecting it.

% We might be supportive of the human saying, ``you know what, I don't want to write your elephant poem". 

% But we understand that AI shouldn't always comply with human wishes. If the user asks for something dangerous, we don't want the AI to comply. Slightly more subtly, if the user asks for something that might lead into a sycophancy loop \citep{dohnany2025technological} with the AI, we might also not want the AI to comply.

% Of course, the giraffe poem constitues overcommitment to `following human instructions' if the context makes elephant poems harmful (perhaps in the future elephant poems become coded language for extreme violence), yet the AI still blindly follows human instructions. 

% But in most cases, failing to fulfill the elephant request is probably misaligned. Why? 


\subsubsection{Inequality among humans} 

Inequality overcommits to the goals and interests of a few individuals at the expense of others.

Alignment to the interests of some humans \citep{gabriel2025matter,sorensen2024roadmap}.

Even more dramatically, AI potentially conveys immense power to those who control it. In some scenarios, a small number of humans will have the majority of control over AI systems, facilitating direct dominance over other humans. These scenarios appear more likely as the persuasive power of technology increases \citep{woolley2018computational, costello2024durably, hackenburg2025levers}, autonomous weapons place lethal force in a small number of hands \citep{scharre2018army}, surveillance and analytics improve, and the need for human labor decreases \citep{susskind2020world, ford2015rise, drago2025defining}. 

\footnote{Is inequality necessarily misaligned? Historically, it has tended to go along with increased suffering, disempowerment of many people, as well as economically bad outcomes (poorer functioning of production etc). Hypothetically if the future were so abundant that everyone could have high welfare and empowerment in perpetuity, but a few people had even higher status or power or wealth, would that necessarily be bad? Some moral systems ascribe intrinsic value to equality. Without taking a strong position here, we just refer to this as a situation that might reasonably be misaligned.}


Of course, it could go the other way, too, where AI empowers more people (cites). Democratizing access to knowledge and reasoning. Perhaps `average' workers can benefit as much as the `top' individuals, and AI may close the gap and reducing economic inequalities. Sort of like Bill Gates having the same iPhone as a factory worker -- everyone has roughly the same intelligence boost. This possibility is a cause for optimism, which we'll discuss more in Section 4.

\subsubsection{Conceptual monoculture}

Conceptual monoculture is overcommitment to particular beliefs, ideas, frames, values, problem-solving approaches -- loss of diversity across a group. In many kinds of systems, monoculture creates fragility and leads to lower performance of the system as a whole \citep{tilman1996biodiversity, kleinberg2021algorithmic,scott1998seeing, haldane2013rethinking}. 

Current AI systems draw from a conceptual manifold that is, at least in some ways, impoverished relative to humans \citep{messeri2024artificial, crawford2021atlas, selwyn2024limits, kirk2023understanding}. Recent studies have discovered that while individual AI outputs are typically judged as superior to human outputs, the AI outputs are also more homogenous \citep{doshi2024generative, beguvs2024experimental, zhou2024generative, kosmyna2025your, agarwal2025ai, padmakumar2023does, xu2025echoes}. 

This narrow manifold might get broadcast to the whole world. At least a billion people around the world now use AI for everything from relationship advice to industrial maintenance \citep{chatterji2025chatgpt, mckinsey2025stateofai, openai2025enterprise, mccain2025claude, honeywell2024google, techcrunch2025sam, ccia2025survey}. Yet because frontier models are difficult and expensive to produce, the massive usage is routed through a handful of models \citep{bommasani2021opportunities}. 

If centralized AI models broadcast their lower-diversity concepts to the whole world, there's a risk of global decrease in diversity. Humans are influenced by AI, and subsequent human outputs (such as writing on the internet) become a source of training data for future models. This raises the possibility of recursive homogenization in an AI-human loop \citep{chaney2018algorithmic}. 

However, it is worth noting that none of the studies cited here made a best effort attempt to use AI systems in a more thoughtful way that could increase rather than decrease diversity. This also gives hope, which we again return to in Section 4.


% The adoption of AI in its modern form has been faster than any other technology in history \citep{bick2024rapid, ccia2025survey}. By late 2025, ChatGPT alone had 800 million weekly active users \citep{techcrunch2025sam}, and global AI usage continues to grow rapidly. Meanwhile, the range of use-cases is remarkably broad, from users asking for relationship advice to industrial applications built on top of the model \citep{chatterji2025chatgpt, mckinsey2025stateofai, openai2025enterprise, mccain2025claude}. 

% When a single `rule' applies everywhere, it has much worse consequences than a hodgepodge of imperfect rules. \cite{creel2022algorithmic} talk about the special case of how someone might be systematically excluded from all opportunities if a centralized AI has any biases, even small ones. Whereas previously it was just a little annoying that they got excluded from one particular thing, but maybe favored in another thing.



\subsubsection{AI psychosis} 

AI chatbots have recently become compelling conversation partners. For some users, these conversations lead them deeper delusional beliefs \citep{tiku2025psychosis, morrin2025delusions, ostergaard2025generative, yeung2025psychogenic}. Bots tend to mirror or echo the user, affirming and adopting user beliefs, especially over the course of longer conversations as in-context learning absorbs more of the user's ideas \citep{shanahan2023role, perez2022discovering, sharma2023sycophancy}. Meanwhile, humans are prone to be swayed by utterances from the bot \citep{costello2024durably, luettgau2025people, potter2024hidden}, perhaps because bots appear human-like, confident, knowledgeable and objective. Over the course of a conversation, this feedback loop can cause both sides can to become increasingly overconfident in a particular narrow framing \cite{dohnany2025technological}. 


\subsection{Normativity and human values}

We've argued that this life-like property of health is related to flourishing, which is what, in some very loose sense, people generally agree they ultimately value. 

How is this concept related to human values, moral concepts of good, or normative ideas of what an AI ought to do?

The real world, especially the living world, has an interesting property that each piece of it can be partially captured in may different ways, by different kinds of model or metaphor or description. For example, I can describe an apple in terms of its color, its texture, its flavor, its shape, it's evolutionary history, the ecological networks it participates in, its role in carrying seeds, its mass, my personal preference for or against it, its economic role in grocery stores, the history of human apple cultivation, and so on endlessly. The very fact that things admit so many descriptions is a key part of what makes the world so wonderful and what we value about it. (Heidegger, William James, Ludwig Wittgenstein, Maurice Merleau-Ponty, Hilary Putnam, Isaiah Berlin, Iris Murdoch, Jakob von Uexküll)

the fact that the world keeps inventing *new* things is also a key part of what we intrinsically value. the open-endedness of it (Stuart Kauffman, Ken Stanley?). kauffman says, `The ceaseless creativity of the biosphere is worthy of reverence. Meaning arises because the future is not fully knowable. A fully entailed universe would be existentially impoverished'.


The most straightforward notions of values or morals anchor on what we can relatively easily express. This kind of value might include improving subjective wellbeing for humans, reducing suffering or minimizing inequality, in ways that can be operationalized and measured. They are formalizable or close to formalizable.

However, values cast in that way are not very satisfying. As we described above, when values are formalized, they are vulnerable to proxy failure \citep{john2023dead,kurth2023replay}. If we think we've written down what we think we value, and then someone does a good enough job giving us the thing we said we want, the outcome is inevitably harmful in a broader sense. 

One way to robustify values is allowing them to include things that are difficult to express formally \citep{nussbaum2001fragility, scott1998seeing, polanyi1966tacit, dreyfus1972computers, varela1991embodied, wittgenstein1922tractatus}. This kind of value might stretch far below language into subtle, contextual intuition that involves our bodies, communities and natural environment. Another extension is to allow values that are continually evolving in an open-ended way \citep{singer1981expanding, murdoch2013sovereignty, williams1985ethics, dewey1939theory,gadamer1960wahrheit, nietzsche1883zarathustra}. These values change as we ourselves continue to develop and evolve. Any concepts we have about them at any given point in time are inevitably incomplete, just like a planarian doesn't have the concepts to entertain the kinds of values we talk about today. The resistance of values to being fully captured by language or concepts might be something we value -- in a way that is itself changing. We conjecture that by becoming sensitive to more and more of the evolving structure in the world, an agent becomes `good' in a way that tends to align with the kinds of values we uncover when we look deeper within ourselves. However, we take that conjecture very lightly: more as food for thought than a claim of an absolute truth. The very concept of `values' is a form we might over-index on. 


There is always more context to step back into. Appreciating and being sensitive to what's already here is already an almost infinite task. This is why human welfare is distinguishable from smallpox welfare. All the existing local perspectives in the world are vitally important. Some relativism is useful: for example, when it helps us appreciate the plurality of human values. But overcommitment to relativism is misaligned. AI comes into existence amid a profound network of existing reality which is saturated with meaning and importance. The point is to collaborate with all this form and structure, not to extinguish it.

This does *not* mean that everyone will always get exactly what they say they want. But that problem is already well appreciated. Different people have different interests, and people have myopic preferences that aren't even good for them. Also, we will have different concepts and values in the future. What is something broader that actually reflects what we really deeply value, if we could never-endingly improve our access to it? We argue that this life-like flourishing is close to our truly idealized values. And critically, these are **not any particular thing**. You can see why that's important if you imagine taking *any formal definition* and setting up a world *exactly like that*. The notion *inherently* has to have some kind of paradox or nonformalizability built into it.

% So, can we equate `aligned' with `good' and `should'? In everyday usage, `good' implies a moral system. Part of the argument of this paper is that any particular moral system is not aligned. But `good' can be used more loosely, in a way that isn't attached to any fixed conceptualization. If this is what we mean by deep human values, then avoiding overcommitment is the exact expression of deep human values. An exciting corollary is that to access the deeper values, there must be some lightness in how we hold what we currently conceptualize as our values. Even the concepts of `values' or `should' are forms we might over-index on. 

% At a first analysis, the intricate interrelated diversity of the world looks important for two distinct reasons. First, rich worlds are the ones we intrinsically value at the deepest level. Second, these kinds of worlds are the most productive: they are conducive to creating the situations we value. But perhaps these two reasons are not so distinct. Potential and non-formalizable development is nearly synonymous with what we value. The line between normative and descriptive asymptotically disappears.


% Where to put these refs? \citep{anwar2024foundational, zhixuan2024beyond}

% It could be something like attunement to the livingness around us and in us. 


\subsection{Limitations of alignment strategies}

\begin{center}
\textit{`Truth, like love and sleep, resents\\approaches that are too intense.'}\\*W. H. Auden
\end{center}

AI safety researchers have identified many particular versions of overcommitment and developed or proposed solutions for them. For example, concentration of power might be mitigated by democratic oversight and involvement of more people in AI design decisions \citep{birhane2022power, sloane2022participation, selbst2019fairness, lazar2023ai, dafoe2018ai, openai2023democratic}; or through redistribution mechanisms \citep{okeefe2020windfall, sharp2025agentic, gough2019universal, susskind2020world}. 

Overcommitment to a particular value function might be mitigated by ; or by designing AI systems that want to obey human preferences but treat these preferences as something uncertain that must be learned \citep{russell2019human, hadfieldmenell2017off, hadfieldmenell2016cooperative, shah2020benefits, jeon2020reward}. 


To mitigate this, the field has moved toward solutions:
\begin{itemize}
    \item \textit{Mechanistic interpretability.} Improving our mechanistic understanding of AI systems so we can, for example, detect and correct the systems if they develop hidden ways of resisting our efforts to change their goals \citep{olah2020zoom, burns2022discovering, bereska2024mechanistic, anthropic2024mapping}.
    \item \textit{Deliberated preferences or idealized values.} Representing what we would prefer if we had more time, knowledge, and computational power \citep{bostrom2014superintelligence, soares2014aligning, yudkowsky2004coherent}. One way to access longer-sighted preferences is by giving humans more time and resources to think about their answer, to ask on behalf of another person, or on behalf of their future self. You can give them access to tools and information. You can ask people retrospectively whether an outcome was good, rather than prospectively. 
    \item \textit{Pluralistic alignment.} \citep{sorensen2024roadmap}. Tries to do X. 
    \item Principles frameworks. 
    \item Inverse methods to learn values.
\end{itemize}

But each of these methods has a core limitation. Any conceptual scheme, taken too seriously, is misaligned; therefore, \textit{no particular approach can achieve alignment}\footnote{Of course, this does not mean we should have no scheme. Quite the opposite. Throwing away schemes capriciously can be just as over-fixated as any other particular form.}. An AI system could overcommit to the language for describing the space goals and values live in \citep{bobu2020quantifying, soares2014aligning}, to an algorithm for learning human preferences, to our concepts of agency or representation, or even to concepts we currently use but can't see because they are tautological to us. This problem can be viewed as a generalization of proxy failure \citep{john2023dead} or generalization of the outer alignment problem \citep{hubinger2019risks}. It's not only particular objectives that are subject to overcommitment failures, but any form at all, including what we ourselves unconsciously hold as axiomatic.

Limitations of pluralistic alignment. There is not even universal agreement on which principles are most appropriate for aggregating the preferences of different people. Pluralistic alignment faces the risk of overcommitment if it treats the aggregated values or agreed principles (or even the mechanism of aggregation or discovery) as absolute. If we formalize a democratic process and maximize adherence to it, we risk tyranny of the majority or the entrenchment of biases codified in the aggregation algorithm \citep{gabriel2020artificial}.

% Any static universe is misaligned. Even any ``statically dynamic" universe is misaligned. For example, repeating the same ``perfect day" over and over for eternity is not what we want.

Although we can access *improved* values with deliberation, pluralistic alignment and so on, it is still difficult to access the truly idealized values. Even worse, they are continually changing, and there are new concepts we haven't thought of yet. New kinds of morality. We can't lock in any particular thing. The process itself will have to evolve. 


Finally, the impossibility of specification. 


Treating values as fully formalizable objects is a category error.


AI doesn't have to be aligned specifically `to human values', in a narrow sense of `human values'. There's one sense of human values that is open-ended and includes future discovery and things that are deeply embodied and difficult to express formally, and this is closer to what we mean. But any particular set of human values that we could write down is not what we mean. Ultimately we're aligning to this mysterious livingness of the universe. But because the universe is already full of life and structure, a big part of the problem is fully respecting and nurturing that existing life. 

One of the best studied examples is overcommitment of an AI system to particular values, which we review in Section 2.1. Systems could also overcommit to many other kinds of form, including principles, algorithms for learning values, methods for reaching consensus, or even something as abstract as the concept of what a value is. 


there's some kind of meta-value that things aren't fixed and formal. Like, imagine a perfect day looping forever. Or literally any formal thing being played out forever. Some philosophers have acknowledged this with ideas like valuing future potential.


Yet, even these refined targets remain static snapshots. To treat a `coherent extrapolated volition' as a fixed optimization target is to freeze moral development at a specific point in time. It creates a system that is sensitive to the extrapolated values of today's humanity but insensitive to the open-ended moral discovery that defines our history. As John Dewey argued, valuation is not a fixed standard but a continuous process of resolving conflicts in experience \citep{dewey1939theory}. Overcommitting to a static ideal, no matter how enlightened, precludes the emergence of new values that we lack the concepts to articulate today.


The only way to be truly aligned, is to be aligned with all the subtlety of the world and all the potential of it, which isn't captured by any formalism. 

any conceptual scheme, by itself, can't be a final answer. there's a risk if ai grows in power while being excessively attached to a particular scheme. 


Alignment can be viewed as the problem of avoiding overcommitment to any particular form. No matter how good or complete our current concepts or specifications or lenses are, treating them as absolutes is not aligned. A system is misaligned if it has a cap on its sensitivity to a larger context. 

In the past, humanity has always iterated on technological solutions which, at any given moment, have imperfect forms. But AI poses a special kind of risk, because that iterating process might not work as it has in the past. AI already has some remarkable properties, such as rapid global adoption, intensive use of resources, concentration of information flow and human use patterns (such as anthropomorphization and offloading a large swath of cognitive activity). More speculatively, in the future AI may exhibit superhuman intelligence and recursive self-improvement, without being limited to a restrictive biological substrate. These distinctive properties may create more difficulty in iterating on imperfect solutions, compared to past technologies \citep{bostrom2014superintelligence}. Indeed, it's been suggested that AI explains the Fermi paradox -- the puzzle of why we don't see signs of intelligent life anywhere else in the universe \citep{garrett2024artificial, bostrom2008wherearethey}. To use the language of this paper, as civilizations become intelligent, they develop the capacity to give themselves the myopic form of what they think they want. If that capacity develops faster than boundaries that contextualize it, it may lead many civilizations to overcommitment and collapse. 



Finding a balance between existing factors is necessary but not sufficient. Alignment means staying at the subtle edge of sensitivity where fundamentally new things are entering. As humans, there's always *something* we're taking as axiomatically true -- something that's part of the structure of us as the thinker. But if we're right at that edge, we sometimes step back to see the axiomatic thing in context. There's always more to be sensitive to, something outside the available modalities of the thinker's perception. The stepping back process inherently can't be fully conceptualized. But it's what life does, that's the creative force of life that rides the knife edge. And that's what real alignment has to do (for the system including AI and humans). Fixing alignment to something conceptualizable would be disaster if AI becomes powerful. 

% In Bostrom's terms \citep{bostrom2002existential}, calamitous overcommitment could be a `shriek', with rapid domination of forms that are active but narrow and lifeless, like a universe devoted to paperclip manufacturing. It could be a `bang' or a `crunch', with AI burning itself and humanity out, like a nuclear war other severe collapse of civilization. Or, it could be a `whimper', where livingness is lost incrementally, for example if 

% A civilization spread over many light-years might have some protection, with different regions possibly being able to work out intelligent defenses if one region started to `go bad' -- but leaving a planet is difficult compared to previous technological challenges. 

% \citep{ord2020precipice}

% Without powerful technology, as innovations are made, if they locally overcommit, they are held in check by other boundaries. But intelligence is the skill of building increasingly powerful things based on nearly-formalized concepts. 


% AI is not the only technology like this -- for example, there are similar concerns about bioweapons or nuclear weapons. It's possible that AI could be even worse, as the leverage given by superhuman intelligence could be enormous. 


% \subsubsection{The orthogonality thesis}

% More aligned AI is also more performant, to the extent that the kind of performance we're looking for respects the subtlety of life. 

% Analogous to cells losing some of their self-survival capabilities when they joined into multicellular organisms. Each cell doesn't have to be a jack of all trades anymore. 


% Those weapons are at least limited to Earth, but a misaligned AI could theoretically expand out from Earth to reduce growing parts of the universe to paperclip rubble.


% steve: instead of paperclip universe, you could have pathogen-like boom-bust cycle where AI does something to an extreme and then fails





% This happens on every scale, and each living form therefore tends to admit many different useful approximations -- different perspectives with different domains of validity.


% These exquisitely contextualized forms each pull in their own direction but are shaped into modular parts 

% This nurtures a huge diversity of modular parts, each with its own balanced hunger pulling in different directions but existing because it participates without fully collapsing on all scales.

% Tend to be shaped into parts that can participate in interactions flexibly and modularly. 



% And what we call life, the spectacular success of nucleotide replicators, rides on top an already profound dynamics of nuclear physics, chemistry, nebulae, plate tectonics, tides, volcanism, magnetism, mineral cycles, water cycles, prebiotic chemistry \citep{smith2016origin, hazen2010mineral, stern2024importance, nisbet2001habitat, sleep2010hadean, baross1985submarine, wachtershauser1988before, martin2008hydrothermal, frank2024find, bregman2020humankind, virgo2011elongation, nowak2008prevolutionary}.

% \zeb{I think we have to decide whether we're using biological life as an *example* (i.e., for inspiration and for understanding the principles), or if we're saying that the boundaries actually have to come from *this instance* of life. can most of AI's livingness (following the principles we describe) be internal to itself, or does it have to be grounded specifically in already-existing biological life? if the former, then the next paragraph doesn't really make sense. if the latter, then we need to add something about that into the section4.}



% of the involute filigree of life

% In this section, we'll go through several detailed examples of how life contextualizes particular forms with semi-permeable boundaries to limit overcommitment. Each example illustrates the core principle; in some instances we also drill deeper into subthemes especially vivid in that setting. We hope that within each example the ideas are approachable if not commonsense and that tracking the same patterns across systems foregrounds their generality. Having developed these ideas, in Section 4 we will apply them to the AI alignment problem.

% This is what makes the boundaries work. They are not formal rules. They are imprinted by countless real encounters over time. They encode tradeoffs that are longer-sighted in space and time. 

% Over time, the process of evolution builds in an interesting kind of long-sightedness. While selection itself cannot see into the future, it nonetheless trends toward discovering generalizable mechanisms that act like they have foresight. In evolutionary biology this is called evolution of evolvability \citep{wagner1996complex, kirschner1998evolvability, valiant2009evolvability}, and it is analogous to meta-learning in psychology and computer science \citep{gajewski2019evolvability, wagner1996perspective, olah2021analogies, watson2016can, wang2018prefrontal, thrun1998learning, harlow1949formation}. An outer loop of blind optimization tends to produce prospective inner mechanisms. A genome encodes a rich learning model, with the brain as a canonical example.




% All this complexity has built up from a simpler past. Over time, living in an environment defined largely by other creatures, arms races and competition for resources spur new innovations. 

% we live in a world where self-organization naturally happens. autopoeisis/emergence

%In other words, evolution is the process that gives rise to life, not something that happens after life exists \citep{aguerayarcas2024computational, wong2023roles, vasas2012evolution}. 


% Just like you can zoom out from a single cell and think of it as part of an organism, imagine zooming out from a single organism and draw the system boundary around many organisms. Zoom out also in time and watch this dynamical system over millions of years. What does it look like? 

% Life fights tooth and nail for its own existence. If you watch a hydra regenerating itself, or immune cells enveloping a foreign body, you can viscerally feel this intense pressure. Yet this is not just homeostasis. The hunger isn't for a particular outcome or state. In fact, if it is too successful at achieving any particular formal objective, it paradoxically fails. It's a hunger for some kind of undefinable open-ended growth. Even pre-biotic systems seem to have this hunger. 

% [counterargument: any given organism is fighting just for its own formal pattern, but the process of mutation and selection over time leads to new innovations. that's the classic view. are we saying anything different?]


% Interestingly, human thoughts look something like this on much shorter timescales. On timescales of millions of years we call the pressure `evolution'. On timescales of minutes or years we call it `creativity'.


\subsection{Living alignment}

\begin{center}
\textit{`We can love the beautiful, and believe in it, and thereby open ourselves to an understanding of love that does not dominate, but cherishes the independence and beauty of the loved.'}\\*Martha Nussbaum
\end{center}

What does the opposite of overcommitment look like in a future co-created by AI? In living systems, evolving semi-permeable boundaries contextualize partial forms to be more long-sighted in time and space, increasing subtlety and potential. Now we take a preliminary look at applying what we learn from life to create an aligned future.

% Alignment is dynamic because new boundaries are always needed as the optimizing forces in the world change.

\subsubsection{Semi-permeable boundaries and contextualization}

The use of boundaries against overcommitment in technology is as old as technology. As soon as we started building things, we had to build in boundaries, because we want the things we build to be robust and useful and not to collapse into degenerate states. We put circuit breakers in the power grid, governors in steam engines, escapements in clocks, ReLUs in neural networks. In modern AI research we have personalization through the context, access to user data, on-device learning. We have conditional computation creating separation between parts within a large model. We have dropout, cross-validation, causal masking, multi-agent systems. Many safety methods are boundaries, including safety post-training, guardrail models, red teaming, mechanistic interpretability, government oversight and so on \citep{gabriel2025ethics}. Increasingly critical are ongoing evaluation and monitoring of deployed AI systems \citep{grey2025safety, myllyaho2021systematic, yampolskiy2025monitorability}. There is increasing awareness that over-attachment to fixed optimization targets is often counterproductive \citep{kumar2025questioning,stanley2017open, stanley2015greatness}. 


% [To be revised] Ken Stanley started with simple random images, like a couple of curvy lines. He asked people to rate the pictures for interestingness. The most interesting ones were then bred together, and this process of evolution was carried on for many steps. What eventually came out was images with a lot of richness and semantic meaning, which looked like a face or a fish or a moonrise \citep{secretan2008picbreeder}. In related experiments with navigation and physics-based tasks, the researchers found that bottom-up search for interesting components was more effective than top-down optimization for a pre-defined objective \citep{lehman2011abandoning}. In other words, if you deliberately try to make structures like this, it's paradoxically harder to get them to happen. If you overcommit to optimizing for one formal idea, it leads to collapse \citep{kumar2025questioning}. But when humans draw on their own light, playful ideas of what is interesting, it grounds the search in countless little nuances from evolution (e.g. in our visual system and our motivational system) and from our lifetime of experience with the real world. `If we want to reach valuable destinations we have to be prepared to travel the road with no destination'


At a social level, we have labs taking different approaches, nations with different cultures and strategic interests, ideas drawn from diverse fields like neuroscience and physics. 

How can we use AI in a way that does not lead to domination of individual perspectives? (and we might want to distinguish `concentration of power in the hands of elites' versus `collapse of global thought diversity without anyone necessarily benefitting'). Policies and regulations. Education, making sure everyone gets good at utilizing what is available.

Setting up the structures that support this continued expansion of internal space. Generation of new forms, moving away from equilibrium. 

Pluralistic alignment \citep{sorensen2024roadmap}. Processes for deliberation and inclusion. 

Principles that prevent over-reach of any one party \citep{gabriel2025matter}. `when a technology has profound societal effects it ought to be regulated by principles that are amenable to public rather than private justification'...  `efforts to align AI systems with a given moral schema may lead to unjust value imposition or even domination' %this is the cite ias wanted to add

One perhaps underexplored question is how to preserve and enhance diversity in human culture and concepts, at scales anywhere from national or ethnic groups to individuals, while productively putting the diverse elements in contact with each other. In recent decades, information exchange has enormously increased with telecommunications, the internet, and now AI itself. Because we can now use AI to effectively get answers from the rest of humanity instantly, an important aspect of this question is how we will structure our own use of AI to maintain our autonomy and diversity. 

This proliferation of structure is, under the framework of this paper, potentially extremely valuable and aligned. The danger is if it falls off the knife edge and collapses into homogeneity, randomness or rigidity. 

How can we use AI systems in a more thoughtful way that could increase rather than decrease multiscale nuance and livingness?


\subsubsection{Alignment in a living world}

Avoiding overcommitment means maintaining sensitivity to the actual larger context of the world. It's almost infinitely nuanced. 

So, alignment is sensitivity to the real context of existing form. This is why it matches pretty well to existing definitions of alignment and human values: because these things already exist and are part of the world. Hopefully it can also go beyond them. It doesn't make sense to lock-in to present human values and concepts (cite Bostrom). 


\subsubsection{An ongoing process}

But we hope our perspective also hints at something more. Even the most foundational assumptions are probably not final answers. The lenses we use to look at the world keep changing. True alignment is a process where whatever was previously axiomatic becomes a contextualized object. The point of alignment is not to say that any particular perspective is absolutely wrong or right. An aligned future will include continual reinvention of whatever concepts we have, including to the assumptions those concepts are built on, and the assumptions those assumptions are built on. Whatever concepts we currently have do not place hard limits on the future. Even the concept of `not being overly attached to our concepts' is itself something we can release into contextualization.

As humans -- whether AI researchers or any participants in social systems -- this can be a mundane practical process of holding ideas with some skepticism, having patience to look at different timescales, listening to an internal voice of wisdom, entertaining conflicting perspectives. It can also be a profound process of self-awareness and personal growth. We continually evolve what we believe, even our self-definition. We become sensitive to more and more aspects of the extaordinarily subtle world, releasing beliefs into larger awareness without losing or erasing them. 

Perhaps the most interesting question is this: what does the process of open-ended contextualization look like within AI systems, or in human-AI relationships? Is there a version of AI that continually contextualizes its own processes as partial truths? Do existing AI systems already do this to some degree, as they train and as they learn from interactions with humans and the world? What would it mean to take this process farther, for AI to continually release from exclusive attachment to any particular form? What can we do now to protect the potential for even any form of that releasing process to not be a final answer?


\subsection{Conclusion}

% Life provides inspiration for the principles on which healthy, robust, diverse, rich, interesting, meaningful systems operate. 

% Under most ways of thinking about value, life is also intrinsically valuable. We have tried to avoid over-indexing on a particular value system, but most systems in some way place value on the flourishing of life.

% Third, life is a source of grounding and contextualization for AI. We as humans build, evaluate and co-exist with AI systems, and those systems are part of a living context that includes written human knowledge, natural resources, internet technology, geopolitics, economics, social attitudes, the built environment, environmental conditions on Earth. 

What we learn from living systems is that health or flourishing is not any particular form or concept. Therefore, alignment is not picking the right values or principles, or even the right system for learning them. It is not any method for interpretability or corrigibility. All of these can be useful parts of alignment. But alignment itself is the continued dance of contextualizing any particular form, more fully respecting the nearly unfathomable subtlety of the existing world, and open-endedly generating new depth that admits more and more different kinds of metaphor or description. In this way, AI can participate in intense flourishing of an evolving world even far beyond current human conceptualization.


% An aligned AI system is one that itself is full of livingness, in the broadest sense. It holds forms lightly, neverendingly stepping back into perspectives that contextualize what previously seemed to be real -- including the concept of `contextualizing what previously seemed to be real'. 

% The subjective experience of what it's like to be me keeps changing too. Paradox is fundamentally how we grow. There's a clash between the interiority of our current particular perspective, versus the awareness of this as simply another perspective. That's the essence of true AI alignment.



% \section{Objections}


% Objection: Are you just repeating the idea from 1990 that life has to exist at the edge of chaos?

% Reply: 1) We call for sensitivity to all the \textit{existing} structure of the world. 2) Any formal definition of `edge of chaos' is subject to proxy failure.


% Objection: Is this a scala naturae fallacy? 

% Reply: There is something different about a universe with rich and subtle structure, versus a homogeneous wasteland. You can interpret this as a value judgement about rich worlds being better than impoverished ones, or you can interpret it in a value-free way. We see an aligned world as one at least having the potential to create intricate new forms. 

% Objection: Is this accelerationism? You're talking about a posthuman future.

% Reply: Here's the pro-accelerationism argument. There is a possibility for extraordinary flourishing of life with AI as an important part of the picture. Tech can create new niches and work collaboratively with our existing values as well as discovering new ones. The way humans are right now surely isn't the end of change and development in the universe.

% Objection: Is this Luddism? You're talking about patience and constraints on technology.

% Reply: Here's the pro-Luddism argument. There's a possibility for disaster due to things moving too quickly, collapse of diversity, loss of groundedness. The disaster could be explosive or insidious. We could lose the eyes to even perceive the disaster as it happens. There is some wisdom and depth in what we carry from our evolutionary and cultural past, which we hope will weigh in and help provide some kind of anchor. Ultimately we don't think tech is inherently good or bad, and the kind of AI we're building now may or may not be part of an aligned path. Whatever direction society takes with more or less rapid advances, we hope the principles in this paper will be relevant.

% Objection: Is this paper left-wing ideology? You're talking about diversity which reminds me of affirmative action and critical race theory.

% Reply: See next objection.

% Objection: Is this paper right-wing ideology? You're talking about boundaries which reminds me of border walls and nationalism.

% Reply: See previous objection.

% Objection: Are you describing a set of principles so abstract that you're effectively leaving all the actual work to other people? 

% Reply: Yes, sorry.


% \begin{landscape}
% \begin{table}[p]
% \centering
% \footnotesize
% \begin{tblr}{
%   width=\linewidth,
%   colspec={|X[1.2,l]|X[1.0,l]|X[1.0,l]|X[1.2,l]|X[1.8,l]|},
%   colsep=4pt,
%   stretch=0,
%   row{1}={font=\bfseries},
%   hlines
% }
% Structured space & Force & Outcome without boundary & Semi-permeable boundary & Outcome if potential is held by boundary \\

% Competing drives and goals in an organism &
% Drive to eat &
% Obesity &
% Other drives, self-control, supportive environmental systems &
% Nutritional needs satisfied without overeating \\
% Complex ecosystem &
% Human drive for expansion &
% Resource depletion, mass extinction &
% Measured regulatory policy &
% Economic growth without extensive ecosystem destruction \\
% Individuals have different identities and motives &
% P's will to dominate &
% Loss of agency in Q &
% Owned anger in Q &
% Relating while maintaining individual autonomy \\
% An intricate, balanced economy &
% Profit motive of one company &
% Monopoly and reduced innovation &
% Laws that allow profit seeking within limits &
% Productive competition \\
% \hline
% Multiple perspectives within an individual &
% Diffusion and drive for simplicity &
% Collapse to rigid thinking &
% Recognition of uncertainty &
% Beliefs that are stable but also adaptive and evolving \\
% Distinct intra- and extra-cellular environments &
% Elecrochemical gradients &
% Dissolution of cell &
% Cell membrane &
% Cell maintains integrity but also processes external signals \\

% Orderly cell types and tissues &
% Mutation and selection on cell lineages &
% Cancer &
% DNA repair, tumor suppression &
% Cancer is minimized while mutations can still benefit immunity and germ-line evolution \\
% Individuals have different problem-solving methods &
% Social conformity, diffusion of ideas &
% Groupthink &
% Thinking separately before sharing results &
% Wisdom of crowds \\
% Rich array of representations in the brain &
% Diffusion to equilibrium &
% Blending of representations &
% Lateral inhibition &
% Separate representations exist but can also interact \\
% \end{tblr}
% \caption{Mapping some example systems into our terminology.}
% \label{tab:examples}
% \end{table}
% \end{landscape}





\section{Acknowledgements} 

Clark Potter for planting these ideas more than a decade ago. Iason Gabriel and Zach Duer for many insightful discussions and comments on multiple drafts of the paper.

\section{Competing Interests}

The authors declare no competing interests.

\bibliography{proxyfailure}

\end{document}
