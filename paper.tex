
\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=0.9in]{geometry}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{changepage}
\usepackage{pdflscape}

\usepackage{wrapfig}
\usepackage{tcolorbox} % Required for the pretty box

\usepackage{tabularray}

\usepackage[labelfont = bf]{caption}
\captionsetup{font=footnotesize}

\usepackage[sort]{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}} %Citation-related commands



\title{Living Alignment}
\author{}
%\author{Zeb Kurth-Nelson$^{1}$*, Steve Sullivan$^2$*}
% \date{
% {\small
% $^1$Max Planck UCL Centre for Computational Psychiatry and Ageing Research, London, UK \\
% $^2$Oregon Health and Science University, Portland, OR \\
% *Equal Contribution
% }
% }


\begin{document}
\maketitle

\vspace{20pt}


\begin{adjustwidth}{35pt}{35pt}
\begin{center}
\textbf{Abstract}
\end{center}

We propose a new way to think about AI alignment: as the ongoing process of limiting overcommitment to any form. Each form -- an equation, a genome, a viewpoint, an institution -- is myopic in the sense that it is only a small aspect of the world. When systems overcommit to particular forms instead of lightly holding dynamic relationships between them, the richness and potential of the world is reduced. If aspects of AI systems remain fixed while they gain increasing resource, capability and purview, there is a risk of severe overcommitment. To think about how to approach this problem, we look to life's resistance to overcommitment. What is living today is what managed to trace a path through billions of years along the knife edge between fragility and excess stability, and living systems are impressed with that immense reservoir of historical experience. Living forms contextualize one another with semi-permeable boundaries that support individual forms to develop robust, grounded identities while also flexibly working together. These light and evolving relationships generate fundamentally new forms. Drawing on examples of these processes in natural and human systems, we sketch out how aligned AI systems can participate in rather than overwhelm the subtlety of life.

\end{adjustwidth}
\vspace{30pt}


% cancer spreads, concentrated power reduces human welfare, invasive species choke out complex ecosystems

% surfacing paradoxes by juxtaposing incompatible things

% semi-permeable boundaries contextualize myopic forms as part of larger systems. 



% If you want to jump straight to alignment, it starts at Section~\ref{sec:alignment}. But those arguments will have more color if you read at least a few of the earlier sections first.

% Living systems adaptively adjust boundaries when structure is being flattened. 

% Sometimes homogenization is blending or averaging; other times it is winner-take-all or domination. 
% -- whether agentic like an organism, or non-agentic like the sodium concentration of an extracellular solution --


% Forces, ranging from simple diffusion to the will of an agent, cause excessive blending or overwriting of forms if left unchecked. When this happens, the richness of the world is collapsed.


% a kind of general relativity? lol. things are defined by their interactions... (`ontic structural realism'). or maybe relationships are forms too. getting too stuck in one pattern of relationship is getting stuck in a particular form. 

% each form or arrangement is lightly held. 

% \tableofcontents

In this paper we look at properties of living systems in order to try to better understand the AI alignment problem\footnote{We will use `alignment' as the broadest umbrella term to include `AI safety', `AI ethics', `AI governance', and all other aspects of designing and relating to AI in a way that leads to positive futures.}. Looking across different types of system we see a consistent theme. Healthy living systems are composed of an exquisite variety of intricately co-functioning partial forms; and health or flourishing, in the deepest possible sense, is the opposite of overcommitment to any particular partial form (Section 1). If we adopt this principle, then alignment becomes the problem of avoiding overcommitment (Section 2). In other words, the alignment problem is bigger than anything formalizable.

% like voices in a group, drives in an organism or creatures in an ecosystem

In natural and human systems, a vast array of semi-permeable boundaries protect against overcommitment. Semi-permeable boundaries support light interactions where the individuality and long-sightedness of entities is deepened as they are impressed with contexts at many spatial and temporal scales (Section 3). After exploring these patterns in natural and human systems, we end with an initial gesture toward the implications for development of aligned AI (Section 4).

Any conceptualization of alignment is by our own definition not a final answer. In this spirit, we are not going to try to make an irrefutable logical argument or compel you to accept our perspective to the exclusion of others. Instead, throughout the manuscript we focus on walking through examples to paint a picture and see if the ideas are useful.

% existing as paradoxes for one another and supporting ongoing increase of subtlety. 


\section{Overcommitment}

\begin{center}
\textit{`Defying definition---a word that means ``to fix or mark the limits of"---living cells move and expand incessantly.'}\\*Lynn Margulis
\end{center}

Life is as magnificently fragile as it is ordered. What we see living today is what traced a path exactly along the edge between disintegration and excess stability. Billions of interactions over time have imprinted living things with traces on every scale of the ever-changing contexts they have participated in. Living systems are therefore difficult to fully capture with simple formal descriptions.

To cope with this immense complexity, science applies many different partial descriptions for the different levels of scale and different aspects of the systems. Overcommitment is when the richness that requires these imperfect partial lenses collapses into excess formality. The central observation of this section is that systems are healthy and flourishing when they are not overcommitted to particular forms. 

[todo: expand slightly on the examples that currently only have one sentence (expanding them to eg three sentences each), and also greatly condense the examples that are currently whole subsections (maybe moving whatever material is worth saving to section3). so it would be like eight or so examples in total, but running very quickly through each one, to show how general the pattern is that overcommitment is unhealthy. then we can get faster to the alignment point.]

This point has been made independently in many disciplines. In evolution, overspecialization and homogeneity make species brittle, leading to trouble when environments change \citep{van2004cope, simpson1944tempo, yachi1999biodiversity}. Excessive training for a physical discipline (e.g., extreme ballet) can negatively impact broader functional health \citep{jayanthi2013sports, warren1986scoliosis}. Several variants of psychotherapy advance the premise that rigidity (stuckness in a narrow range of mental forms) is the root of psychopathology \citep{kashdan2010psychological, reich1933character, shapiro1965neurotic}. Institutions and civilizations that ossify in bureaucracy and rigid patterns become dysfunctional \citep{weber1905protestantische, merton1940bureaucratic, olson1982rise}. Stereotypy and rigidity are pathological in physiological systems \citep{canguilhem1966normal, lipsitz1992loss, mackey1977oscillation, sterling1988allostasis}. In general, to regulate effectively, a regulator needs variety in its own dynamical repertoire \citep{ashby1956introduction, ashby1958requisite}. We select a few examples below to go into more detail.

\subsection{Drives and goals}

\begin{center}
\textit{`Life is a balance of holding on and letting go.'}\\*Rumi
\end{center}

Animals experience multiple innate drives, towards nutrition, osmotic balance, temperature regulation, reproduction, avoiding pain and others \citep{saper2014hypothalamus, schulkin2019allostasis, sewards2003representations}. These drives evolved as proxies for evolutionary fitness. By satisfying the drives, we tend to increase our fitness -- like slaking our thirst increases the odds of reproducing before we dehydrate. But each drive is an imperfect proxy, and so overcommitment to one drive actually decreases fitness \citep{kurthnelson2024dynamic,john2023dead, williams1966adaptation, tooby1992psychological}. For example, if calorie intake is maximized without limits, the organism becomes obese and incurs severe health risks. Single-minded pursuit of sex causes relational, occupational, legal and health harms \citep{kraus2016should, carnes2001out}. Overcommitment to a single drive means the organism becomes unwell.

The space of innate drives bleeds into a space of higher-order goals, which is particularly expansive in humans \citep{maslow1943theory, miller1960plans, miller2001integrative, vallacher1987people, balleine2007role, cardinal2002emotion, frank2006anatomy, saunders2012role, o2014goal, schank1977scripts}. We try to plan for our financial future, make scientific discoveries, win a game, fix a garage door, care for the happiness of others. Overcommitment in this space is also problematic. If we focus only on achieving work goals, we can burn out. If we focus only on maximizing our company's reported revenue, without regard for other goals like honesty or adhering to the law, we may be drawn into financial crime \citep{campbell1979assessing, ordonez2009goals, kerr1975folly, burns2006impact}. Goals can be narrow in both time and space \citep{ballard2018pursuit, vallacher1987people, shah2002forgetting, evenden1999varieties}. Narrow in time means being focused on the short term at the expense of the longer-run future. Narrow in space means ignoring other parallel goals. Excess optimization for narrow goals is at the expense of a broader balance of goals -- and at the expense of the health of the organism or other individuals. We suggest that health, in general, can be defined as not overcommitting to a particular form. 

Overcommiting to a particular strategy for satisfying a drive or goal can even come at the expense of satisfying that very drive or goal. In a classic psychology experiment, hungry chickens were placed near a cup of food, but the cup was mechanically rigged to move in the same direction as the chicken at twice the speed \citep{hershberger1986approach}. The chicken could only obtain the food by running away from it. Despite extensive training over multiple days, chickens in the experiment persisted in futilely running toward the food. Their behavior was apparently dominated by the zeroth-order logic ``I want food, food is there, so I'll go there", and thus failed to even satisfy the drive for food \citep{dayan2006misbehavior, van2012information, o2017learning}.

A key point, which we'll return to several times, is that undercommitment is also overcommitment. Undercommitment is the simple form of homogeneity. It's essential that we do locally commit to forms -- while preserving the flexibility of contextualization at a larger scale. The problem arises when a particular goal, mental process or approach runs amok without being contextualized in a larger framework. 

\subsection{Ecosystems}

Each entity in an ecosystem tries to consume resources and proliferate, but if it succeeds too thoroughly, the whole system suffers, often including the successful agent. Healthy, resilient ecosystems depend on avoiding overcommitment or collapse onto particular forms \citep{holling1973resilience, yachi1999biodiversity}.

Prior to the arrival of Europeans, the gray wolf was an apex predator in the region of the Rocky Mountains now called Yellowstone National Park. By the 1920s, wolves had been eradicated to protect livestock and game animals. Without predation, the elk population multiplied and ruinously overgrazed willows and aspens. These trees had held riverbanks in place and supported beaver populations. Loss of beaver dams led to loss of fish and other aquatic species. When wolves were reintroduced in the 1990s, the elk population decreased and many aspects of the ecosystem began flourishing again \citep{ripple2012trophic}. This story is not meant to imply that ecosystems always need to be preserved exactly as they were at some point in the past. But it is clear that the self-centered drives of elk were harmful to the health of the ecosystem when they succeeded to excess. At the same time, the solution is not to remove elk entirely: by trying to optimize their own objectives within a broader context, the elk also contributed to the health of the ecosystem. Invasive species often follow the same pattern as unpredated elk, dominating and impoverishing their new environment \citep{pimentel2005update}.

% Predation supplied a semi-permeable boundary: it placed contextualizing limits on the elk, without preventing them from fighting for their own survival and flourishing. 

Human drives within ecosystems are sometimes left unchecked by natural forces because our behavior and capabilities have been changing so fast on evolutionary timescales. This has resulted in mass extinctions, resource depletion, pollution, disease and conflict \citep{ceballos2015accelerated, kolbert2014sixth, rockstrom2009safe}. We try to achieve certain aims for our own benefit, like resource extraction. But overcommitment to those aims negatively impacts both ecosystem health and our own welfare \citep{shiva1993monocultures, bateson1972steps}.

Of course, one entity's collapse can be another's flourishing. Extinction events in history have been followed by waves of new diversity \citep{feng2017phylogenomics, jablonski2005mass, raup1994role}. When a wolf eats an elk, the health of that elk collapses to zero, yet predation is necessary for the overall functioning of the ecosystem. And as humans proliferate and extract resources, we leave destruction in our wake; yet the extraction fuels explosion of technology, art, music, and human experience.


\subsection{Frames and perspectives} 

\begin{center}
\textit{`Strong opinions, weakly held.'}\\*Paul Saffo
\end{center}

As a Starfleet cadet, James T. Kirk faces a challenging training exercise. He receives a simulated distress call: a vessel is stranded in the Neutral Zone. Attempting rescue would risk war with the Klingons. But ignoring the call would condemn the crew of the vessel to death. The exercise was designed to reinforce the lesson that not every situation has a victorious solution. But Kirk has an insight: this is a training simulation running on a computer. He reprograms the simulated Klingons to be helpful instead of belligerent, thereby rescuing the crew and avoiding war \citep{wiki:kobayashimaru}. 

Kirk stepped outside the mental frame in which there was an apparently unwinnable dilemma. From inside a particular frame, the frame appears to be reality. But there are almost always multiple valid perspectives, each of which is only a partial description of reality \citep{goffman1974frame, de1970lateral, duncker1945on, ohlsson1992information, lakoff1980metaphors, safo2008strong, javed2024big, popper1934logik, korzybski1933science, wittgenstein1922tractatus, heidegger1998humanism, kuhn1970structure}. Famously, `all models are wrong' \citep{box1976science}. Humans have a vast array of available metaphors and concepts, which are not even all consistent or compatible with one another \citep{feyerabend1975against, hofstadter2001analogy, wood2012dead, freud1936ich, adorno1950authoritarian}. The world is too complex for all beliefs to be fully evaluated against each other and reconciled. At any given time, we only access a very few items, and others are largely inaccessible \citep{miller1956magical, hills2015exploration, baddeley2000episodic, dehaene2014consciousness}. Each particular frame or concept is myopic because it doesn't capture the whole world, but collectively they form a powerful toolkit for problem solving and understanding. 

Losing the ability to flexibly shift between different frames or thought patterns runs the risk of obsession or delusion. In obsession, a particular thought pattern or schema is overemphasized to the detriment of healthy functioning \citep{salkovskis1985obsessional, rachman1998cognitive}. In delusions, an entire conceptual framework crystallizes with excessive certainty and is resistant to disconfirmatory evidence \citep{mishara2010klaus, jaspers1997general, american2013diagnostic, heinz2019towards, adams2013computational}. Obsessions and delusions are myopic: they lose sight of most of the world by overcommitting one thought pattern or frame. 

But crucially, the existence of narrow points of view is not a problem. It's necessary. Any point of view is partial, but it doesn't mean we shouldn't have viewpoints. Even obsession can be powerful when we obsess on a problem at work and occasionally achieve good results. A delusion-like framework can seed a scientific revolution. The point is not to shut down narrow concepts. The point is to limit them from becoming the sole and absolute determinants of behavior.


\section{Misalignment as overcommitment}

\begin{center}
\textit{`Growth for the sake of growth is the ideology of the cancer cell.'}\\*Edward Abbey
\end{center}

We will return in Section 3 to more examples of overcommitment as the opposite of health, and there we will look at how living systems avoid overcommitment and maintain health. But with the beginnings of an operational definition of overcommitment, we now tie it to the AI alignment problem. Alignment means, in some very general sense, working toward futures that are healthy and flourishing. 

Therefore, we propose that alignment means avoiding overcommitment to any particular form. To give a flavor of this mapping, we start with a few examples of alignment failures that are obviously problems of overcommitment: optimizing for shallow goals, concentration of human power and conceptual monoculture. Then we'll look at a more subtle example. And we'll ask about the relationship between this broad concept of alignment and moral and normative notions of `good' and `should'.

\subsection{Optimizing for shallow goals}

% The alignment problem is sometimes described as getting AI to act in accordance with human values. When framed this way, we quickly realize i

It's difficult to specify what our values are, or the way we want the world to be. Any way we have of writing down or formalizing what we want misses important things. If we ask a powerful AI system to optimize for that formalization -- in other words, to give us what we've said we want -- the results are paradoxically disastrous \citep{krakovna2020specification, russell2019human, grossman1986costs, hadfield2019incomplete, zhuang2020consequences, gabriel2020artificial, wiener1960some, amodei2016concrete}. Nick Bostrom gives some striking examples \citep{bostrom2014superintelligence}. Suppose part of our value function -- part of the objective we give to an AI system -- is to find a cure for cancer. A super-powerful AI system, trying its very best to do exactly what we've asked for, could plausibly create cancers in millions of humans in order to experiment more efficiently to find a cure. Or, imagine the AI's objective is to increase the humans' subjective experience of wellbeing. Under reasonable definitions, achieving this objective is most efficiently achieved by imprisoning humans and directly stimulating neurons to trigger our experience of wellbeing. Doing too good a job of optimizing for any formalized goal is misaligned by being overcommitted to the myopic form of that goal.

\subsection{Concentration of human power} 

As a second clear example of misalignment-as-overcommitment, AI potentially conveys immense power to those who control it. In some scenarios, a small number of humans will have the majority of control over AI systems, facilitating dominance over other humans. These scenarios appear more likely as the persuasive power of technology increases \citep{woolley2018computational, costello2024durably, hackenburg2025levers}, autonomous weapons place lethal force in a small number of hands \citep{scharre2018army}, surveillance and analytics improve, and the need for human labor decreases \citep{susskind2020world, ford2015rise, drago2025defining}. Concentration of human power overcommits to the goals and interests of a few individuals, at the expense of others.

\subsection{Conceptual monoculture}

At least a billion people around the world now use AI for everything from relationship advice to industrial maintenance \citep{chatterji2025chatgpt, mckinsey2025stateofai, openai2025enterprise, mccain2025claude, honeywell2024google, techcrunch2025sam, ccia2025survey}. Yet because frontier models are difficult and expensive to produce, this massive usage is routed through a handful of models \citep{bommasani2021opportunities}. 

% The adoption of AI in its modern form has been faster than any other technology in history \citep{bick2024rapid, ccia2025survey}. By late 2025, ChatGPT alone had 800 million weekly active users \citep{techcrunch2025sam}, and global AI usage continues to grow rapidly. Meanwhile, the range of use-cases is remarkably broad, from users asking for relationship advice to industrial applications built on top of the model \citep{chatterji2025chatgpt, mckinsey2025stateofai, openai2025enterprise, mccain2025claude}. 

Centralization carries a risk of conceptual monoculture. Current AI systems draw from a conceptual manifold that is -- at least in some ways -- impoverished relative to humans \citep{messeri2024artificial, crawford2021atlas, selwyn2024limits, kirk2023understanding}. Recent studies have discovered that while individual AI outputs are typically judged as superior to human outputs, the AI outputs are also more homogenous \citep{doshi2024generative, beguvs2024experimental, zhou2024generative, kosmyna2025your, agarwal2025ai, padmakumar2023does, xu2025echoes}. Since humans are both influenced by AI and a source of training data, there's an additional risk of recursive homogenization \citep{chaney2018algorithmic}.

Conceptual monoculture is overcommitment to particular beliefs, ideas, frames, values, problem-solving approaches. In many kinds of systems, monoculture creates fragility and leads to lower performance of the system as a whole \citep{tilman1996biodiversity, kleinberg2021algorithmic,scott1998seeing, haldane2013rethinking}. 

% When a single `rule' applies everywhere, it has much worse consequences than a hodgepodge of imperfect rules. \cite{creel2022algorithmic} talk about the special case of how someone might be systematically excluded from all opportunities if a centralized AI has any biases, even small ones. Whereas previously it was just a little annoying that they got excluded from one particular thing, but maybe favored in another thing.

\subsection{Elephants and giraffes}

The scenarios described above are straightforwardly problems of overcommitment. But our proposal is that all misalignment can be understood as overcommitment. To test this idea, let's look at a kind of misalignment that is less obviously overcommitment: the user asks an AI chatbot to write a poem about an elephant, and the AI instead writes a poem about a giraffe.

We argue that this is a failure of overcommitment. When present-day models fail to follow instructions, the reason is almost certainly not an internal spark of life pulling it in an interesting new direction or an authentic interiority resisting the domination of another's will. Instead, instruction following failures reflect lack of sensitivity to context: overcommitment to shallow patterns. For example, models can collapse into ``shortcut learning'' where they over-rely on superficial correlations (even a single keyword) \citep{geirhos2020shortcut}, get fixated on data that was overrepresented in training \citep{zhao2021calibrate,reynolds2021prompt,xu2024knowledge} or lack flexibility in attending to the right positions in their input \citep{liu2024lost}. Today, we are still in the regime where making AI systems more responsive to human instructions usually involves more subtlety, more sensitivity and less overcommitment.

However, there are important exceptions. We don't want AI systems to follow all human requests. We don't want them to assist with committing violent acts, for example. When the AI system correctly refuses harmful requests, it is applying its own context to avoid overcommitment to human instructions that could lead to greater collapse. In these situations, the AI's designers have effectively decided there's a risk that the user is not fully sensitive to the longer-sighted implications of their own intentions. By extrapolation, as AI systems continue to gain scope, we should expect less direct compliance with human instructions \citep{hadfieldmenell2016cooperative,bostrom2014superintelligence,russell2019human, milli2017should, yudkowsky2004coherent}. Rather than literally fulfilling a request, there might be a better response which achieves a deeper, unstated intent of the user or an outcome aligned with the interests of more people or the longer-term future.

% While we usually expect a chatbot to follow instructions, we don't expect humans to follow instructions in the same way. If a human is asked to write an elephant poem, we don't wish for a world where they are a mindless slave compelled to comply. Of course, there's an asymmetry between humans and present-day AI systems. 

% For systems lacking the contextual richness of humans, fulfilling human requests is often the best way to minimize collapse. 

% Indeed, in a future where AI becomes more like humans, we might accept that it is aligned for the AI not to mindlessly comply with all requests. 

% As AI systems grow in complexity, long-term coherence and participation in social systems, it may become more commonplace that the aligned behavior is not direct acquiescence to a human request, but maybe refining or even rejecting it.

% We might be supportive of the human saying, ``you know what, I don't want to write your elephant poem". 

% But we understand that AI shouldn't always comply with human wishes. If the user asks for something dangerous, we don't want the AI to comply. Slightly more subtly, if the user asks for something that might lead into a sycophancy loop \citep{dohnany2025technological} with the AI, we might also not want the AI to comply.

% Of course, the giraffe poem constitues overcommitment to `following human instructions' if the context makes elephant poems harmful (perhaps in the future elephant poems become coded language for extreme violence), yet the AI still blindly follows human instructions. 

% But in most cases, failing to fulfill the elephant request is probably misaligned. Why? 


\subsection{Normativity and human values}

We've described a concept of alignment that deviates a bit from standard definitions. How is this concept related to human values, moral concepts of good, or normative ideas of what an AI ought to do?

The most straightforward notions of values anchor on what we can relatively easily express. This kind of value might include improving subjective wellbeing for humans, reducing suffering or minimizing inequality, in ways that can be operationalized and measured. They are formalizable or close to formalizable.

However, values cast in that way are not very satisfying. As we described above, when values are formalized, they are vulnerable to proxy failure \citep{john2023dead,kurth2023replay}. If we think we've written down what we value, and then someone else does a good enough job giving us the thing we said we want, the outcome is inevitably undesired in a broader sense. One way to robustify values is to allow them to include things that are difficult to express formally \citep{nussbaum2001fragility, scott1998seeing, polanyi1966tacit, dreyfus1972computers, varela1991embodied, wittgenstein1922tractatus}. This kind of value might stretch far below language into subtle, contextual intuition that involves our bodies, communities and natural environment. Another extension is to allow values that are continually evolving in an open-ended way \citep{singer1981expanding, murdoch2013sovereignty, williams1985ethics, dewey1939theory,gadamer1960wahrheit, nietzsche1883zarathustra}. These values change as we ourselves continue to develop and evolve. Any concepts we have about them at any given point in time are inevitably incomplete, just like a planarian doesn't have the concepts to entertain the kinds of values we talk about today. In fact, the resistance of values to being fully captured by language or concepts might even intrinsically be part of what we value -- in a way that is itself changing. 

So, can we equate `aligned' with `good' and `should'? In everyday usage, `good' implies a moral system. Part of the argument of this paper is that any particular moral system is not aligned. But `good' can be used more loosely, in a way that isn't attached to any fixed conceptualization. If this is what we mean by deep human values, then avoiding overcommitment is the exact expression of deep human values. An exciting corollary is that to access the deeper values, there must be some lightness in how we hold what we currently conceptualize as our values. Even the concepts of `values' or `should' are forms we might over-index on. 



% Where to put these refs? \citep{anwar2024foundational, zhixuan2024beyond}

% It could be something like attunement to the livingness around us and in us. 


\subsection{Overcommitment to any form is misaligned}

\begin{center}
\textit{`Truth, like love and sleep, resents\\approaches that are too intense.'}\\*W. H. Auden
\end{center}

Let's recap how big the problem is. AI safety researchers have identified many particular versions of overcommitment and developed or proposed solutions for them. For example, concentration of power might be mitigated by democratic oversight and involvement of more people in AI design decisions \citep{birhane2022power, sloane2022participation, selbst2019fairness, lazar2023ai, dafoe2018ai, openai2023democratic}; or through redistribution mechanisms \citep{okeefe2020windfall, sharp2025agentic, gough2019universal, susskind2020world}. Value lock-in might be mitigated by improving our mechanstic understanding of AI systems so we can, for example, detect and correct the systems if they develop hidden ways of resisting our efforts to change their goals \citep{olah2020zoom, burns2022discovering, bereska2024mechanistic, anthropic2024mapping}; or by designing AI systems that want to obey human preferences but treat these preferences as something uncertain that must be learned \citep{russell2019human, hadfieldmenell2017off, hadfieldmenell2016cooperative, shah2020benefits, jeon2020reward}. 

% Any static universe is misaligned. Even any ``statically dynamic" universe is misaligned. For example, repeating the same ``perfect day" over and over for eternity is not what we want.

But there is a deeper problem. Any conceptual scheme is misaligned; therefore, no particular approach can achieve alignment. In other words, excess attachment to any particular alignment scheme is misaligned\footnote{Of course, `any scheme is misaligned' does not mean `we should have no scheme'. Quite the opposite. The beauty of the universe is nothing but form. Throwing away schemes capriciously is just as over-fixated as any other particular form.}. An AI system could overcommit to the language for describing the space goals and values live in \citep{bobu2020quantifying, soares2014aligning}, to an algorithm for learning human preferences, to our concepts of agency or representation, or even to concepts we currently use that we can't see because they are tautological to us. This problem can be viewed as a generalization of proxy failure \citep{john2023dead}. It's not only particular objectives that are subject to overcommitment failures, but any form at all, including what we ourselves unconsciously hold as axiomatic.

In the past, humanity has always iterated on technological solutions which, at any given moment, have imperfect forms. But as many people have pointed out, there's a danger that AI presents a unique risk of overcommitment. The process might not work as it has in the past. Because of the extremeties attached to AI, there are paths we could set it on that lead to unrecoverable destruction. AI is not the only technology like this -- for example, there are similar concerns about bioweapons or nuclear weapons. It's possible that AI could be even worse, as the leverage given by superhuman intelligence could be enormous. 

Indeed, it's been suggested that AI is the solution to the Fermi paradox \citep{garrett2024artificial, bostrom2008wherearethey}. As civilizations become intelligent, they develop the capacity to give themselves the myopic form of what they think they want. If that capacity develops faster than boundaries that contextualize it, it might inevitably lead to overcommitment and extinction. Calamitous overcommitment could be divergent, with an ever-expanding spread of some kind of form, like a universe of paperclip manufacturing. Or, it could be convergent, with AI burning itself and humanity out, like a nuclear war \citep{bostrom2002existential, ord2020precipice}.

% Analogous to cells losing some of their self-survival capabilities when they joined into multicellular organisms. Each cell doesn't have to be a jack of all trades anymore. 


% Those weapons are at least limited to Earth, but a misaligned AI could theoretically expand out from Earth to reduce growing parts of the universe to paperclip rubble.


% steve: instead of paperclip universe, you could have pathogen-like boom-bust cycle where AI does something to an extreme and then fails



\section{Boundaries and contextualization}

\begin{center}
\textit{`When forced to work within a strict framework, the imagination is taxed to its utmost--and will produce its richest ideas. Given total freedom the work is likely to sprawl.'}\\*TS Eliot
\end{center}

\begin{center}
\textit{`Nature's imagination is so much greater than man's, she's never going to let us relax.'}\\*Richard Feynman
\end{center}

To start to think about an answer to the big problem, let's look at how life stays light and full of potential despite the constant risk of collapse into one overcommitment or another. In this section we'll go through several examples of how natural and human systems use semi-permeable boundaries to allow forms to emerge while also holding them in a larger context so they are not overcommitted. Each example illustrates the core principle; in some instances we also drill deeper into subthemes especially vivid in that setting. We hope that within each example the ideas are approachable if not commonsense and that tracking the same patterns across systems foregrounds their generality. Having developed these ideas, in Section 5 we will apply them to the AI alignment problem.


\subsection{Laws}

\begin{center}
\textit{`Unity without uniformity and diversity without fragmentation.'}\\*Kofi Annan
\end{center}

Individual actors in a society and in an economy each act from their own perspective. Each actor's perspective is myopic. Of course, myopia does not always mean selfishness in the sense of valuing only one's own wealth or physical wellbeing \citep{crockett2014harm, becker1974theory, henrich2001search}. But an actor cannot know everything or fully understand the motives and beliefs of others. 

Without boundaries, social systems tend to overcommit to one actor's perspective or interests. This domination results in collapse and an impoverished system. For example, a company's profit motive, if unresisted, leads to suppression of competition, deception, and exploitation of individuals \citep{dalrymple2019anarchy, baran1966monopoly, goldacre2014bad, smith1776inquiry, bakan2006corporation}. An individual's desire for power and social dominance can lead to disempowering or silencing of others and even direct infringement on the autonomy and wellbeing of others \citep{hawley2003prosocial, tepper2000consequences, sidanius2001social}. Even genuinely held, ostensibly prosocial beliefs lead to conflict and suppression when different groups have different perspectives \citep{haidt2012righteous, scott1998seeing, greene2013moral}.

Law, when it works well, is a boundary against dominance of any actor's motives. A person is motivated by a dispute to kill another person, but the law forbids murder. A business tries to maximize its success, but the law bans environmental exploitation, false advertising, and anti-competitive practice. 

Effective laws do not annul the myopic drives of particular actors, but rather \textit{contextualize} them within a larger system. Under ideal circumstances, the boundary of the law reroutes the energy of a myopic drive in more productive direction. A would-be murderer, unwilling to face the penalty of the law, might seek a dispute resolution establishing a stable framework that supports future prospering of both parties. A business wanting to expand, but constrained to act within the law, is driven to build better products \citep{wu2011master, ashford1985using, ambec2013porter}. 

Of course, intelligent agents do not necessarily accept boundaries set on their desires. The law must adapt as its loopholes are discovered. Like other systems in the living world, it forms an evolving network of boundaries \citep{campbell1979assessing, ordonez2009goals, kerr1975folly, burns2006impact}. The evolving laws gradually acquire grounded wisdom as they are tested against many different situations and motives, a phenomenon we will investigate in Section 4.



\subsection{Problem solving in groups}

\begin{center}
\textit{``I could also observe, time and again, how too deep an immersion in the math literature tended to stifle creativity."}\\*Jean Écalle
\end{center}


\begin{center}
\textit{`There's more exchange of information than ever. What I don't like about the exchange of information is, I think that the removal of struggle to get that information creates bad cooking.'}\\*David Chang
\end{center}


In 1968, the nuclear submarine USS Scorpion vanished en route from the Mediterranean to Virginia \citep{sontag1998blind, craven2002silent, surowiecki2005wisdom}. The Navy started a search, but the amount of ocean where the vessel could be was enormous. John Craven, Chief Scientist of the U.S. Navy's Special Projects Office, devised an unusual search strategy. He assembled a diverse group of mathematicians, submarine specialists, and salvage operators. But he didn't let them communicate with each other. Each expert had to use their own methods to come up with their own estimate of where the Scorpion should be. Craven then aggregated the independent estimates into a single prediction. Astonishingly, the wreckage was found only 220 yards from this spot. 

When solving problems, different people bring different perspectives and approaches. Each method processes the available data using a different toolkit. Under favorable conditions, combining the approaches of multiple contributors yields better results than any individual working alone. This ``wisdom of crowds" effect has been documented in numerous domains of problem solving \citep{surowiecki2005wisdom, condorcet1785essai}.

However, there is a perpetual danger of overcommitment. The wisdom of crowds is diminished if a group lacks diversity, either ab initio or as a result of within-group communication and influence \citep{surowiecki2005wisdom, hogarth1978note, ladha1992condorcet, hong2004groups}. Controlled experiments, as well as analyses of key decision moments in real groups, find that groups collectively reach irrational or suboptimal solutions when diverse and dissenting viewpoints are lost to a narrower set of ideas \citep{anderson1997information, stasser1985pooling, flowers1977laboratory, frey2021social, becker2017network, janis1972victims, bernstein2018intermittent, diehl1987productivity}. Unstructured communication methods like open discussion have a special vulnerability of rhetorical force dominating over epistemic merit. At the same time, sharing information is essential for the benefits of group wisdom and cooperative behavior. There is therefore a tension between overcommunication where diversity is lost and undercommunication where diversity is not leveraged. 

The crux is semi-permeable boundaries: wisely transmitting the right information at the right time, in the right way. Thoughtful strategies for communication are like transmembrane channels that allow the right molecules in and out of the cell at the right time. They protect the existence of diverse problem solving approaches while also allowing productive interaction between them. Semi-permeable boundaries are contextualizing: they retain individuality while also situating it within relationships to other entities. 

Many varieties of semi-permeable boundary are effective in boosting group performance, including: creating decentralized topologies where group members only communicate with nearby neighbors \citep{becker2017network, mason2008propagation}; defining rules that incentivize acting according to one's own belief rather than following the crowd \citep{hung2001information, bazazi2019self}; modeling the strengths and weaknesses of each group member \citep{welinder2010multidimensional}; promoting leadership styles where one person's views are less likely to dominate \citep{flowers1977laboratory, leana1985partial}; and periodically breaking up into subgroups or rotating membership \citep{janis1972victims, hauer2021science, trainer2020team, straus2011group, feldman1994whos, sutton1987selecting, kane2005knowledge, wu2022membership, owen2019avoid, vafeas2003length, bebchuk2005costs, baron2005so}. In a later section, we will look at boundaries within an individual, such as skepticism, that make it easier to interact with others without overwriting one's own beliefs.

A particularly important boundary for group problem solving is simply giving members the space to work independently before communicating \citep{frey2021social, surowiecki2005wisdom}. In the case of the submarine search, experts weren't allowed to communicate while forming their own estimates; the estimates were later aggregated in a principled way by Craven. Analogously, science historians argue that partial intellectual isolation has at times been beneficial for the emergence of deeply new ideas. Einstein's relative independence from the advanced mathematical techniques of contemporaries like Hilbert led to a theory of general relativity grounded in deep physical insight rather than mathematical convenience \citep{stachel1989einstein, corry1997belated, renn1999heuristics}. Newton's and Leibniz's famous independent development of calculus, as a result of their mutual isolation, yielded two distinct and valuable mathematical systems that complemented and enriched one another \citep{hall2002philosophers}. 

The benefit of temporary isolation before communicating also shows up in controlled experiments. \cite{bernstein2018intermittent} tasked small groups with solving instances of the traveling salesman problem. Each group was randomly assigned to one of three conditions. In some groups, members could continually see the work of other members as they progressed toward a solution; in some groups members could only occasionally exchange progress; and in some groups there was no exchange. The researchers found that groups with continual information exchange rarely found good solutions. In these groups, typically one individual would stumble on a solution that looked compelling but was actually a dead-end. When this solution was immediately shared with others, it hampered their progress. Groups with occasional or no contact were much more likely to find optimal or near-optimal solutions. 

% We stress that this is not an indictment of connection and communication between group members. Rapid access to information and shared solutions often demonstrably boosts productivity. In some situations the ideal boundary might be working in isolation for months at a time. But in other situations it could be daily meetings with intensive communication, while maintaining the self-confidence to keep pursuing one's own intuition in the face of skepticism from others \citep{sawyer2017group, paulus2003group}. The key is that boundaries support flexible interactions and avoid overcommitment to particular forms.

\subsection{Cells}

\begin{center}
\textit{`It is by avoiding the rapid decay into the inert state of equilibrium that an organism appears so enigmatic.'}\\*Erwin Schrödinger
\end{center}



One of the most reified examples of a boundary in nature is the cell membrane \citep{watson2015biological, alberts2022molecular, bray2019wetware, harold2001way, lane2015vital}. Without the membrane, the pressure of chemical gradients would rapidly homogenize the cell's contents with the outside -- severe overcommitment to a uniform state, collapsing the subtlety of the cell's structure. Thanks to the membrane, both the cell and the outside can exist, a more diverse, less symmetric arrangement \citep{schrodinger1944what, anderson1972more, prigogine1984order, turing1952chemical}. 

Cell membranes are semi-permeable: they prevent the conditions outside from grossly overwriting the inside, but they do not block interactions wholesale. Via the sophistication of the membrane, outside information is selectively gated and transformed. Channels permit certain small molecules to enter but not others, and these permissions are switched on and off according to momentary context. Endocytosis brings larger structures from outside into the cell. Cell surface receptors, when activated by external ligands, initiate intracellular signaling cascades that little resemble the ligand: an even more heavily curated form of influence. These and other processes allow information from the outside to influence the inside -- not in a totalitarian way but in a nuanced way, mediated by the intelligence of the boundary. 

Semi-permeable boundaries put to work the potential energy of the asymmetry between different forms. The same gradients that could annihilate the cell instead drive useful signaling, like action potentials in nerve and muscle cells. Instead of short-circuiting, myopic forces are contextualized to propel the continuation of life. This pattern is common across many kinds of systems and will be important for the alignment problem. We will return to it a few times.

Symbiogenesis is another example of modularity and evolvability \citep{margulis1995what, margulis1986microcosmos}. Why was it easier for mitochondria to merge into cells rather than being evolved from within? It's literally that they have their own discreteness that permits cells to ship them around to serve as local power stations, and this fueled the explosion of complex morphologies in multicellular organisms.

In multicellular organisms, most of the `outside' is defined by other cells. For organisms to work well as a whole, even though the cells are largely `on the same team', it's important that they don't blend into each other. Neurons rely on this principle dramatically, stretching out long processes to almost touch other neurons but then leaving the gap of the synapse. Keeping them separate while also communicating by synapse allows them to collectively hold more information than if they were directly electrically coupled. It also boosts computational power as the signals are transformed by synapses and the nature of this transformation is plastic, storing a huge amount of information. 


Finally, collapse or overcommitment is always relative. For example, programmed cell death is catastrophic collapse at the level of the dying cell, but it can be beneficial or even necessary for the organism the cell belongs to.


\subsection{Sex}

\begin{center}
\textit{`The mere act of crossing by itself does no good. The good depends on the individuals which are crossed differing slightly in constitution, owing to their progenitors having been subjected during several generations to slightly different conditions.'}\\*Charles Darwin
\end{center}


Sex is costly. An organism must find a mate in the vast and dangerous world, and half of the creatures can't reproduce \citep{smith1971origin, lehtonen2012many, smith1978evolution, speijer2015sex, goodenough2014origins}. Yet all known species either reproduce sexually or have some form of horizontal gene transfer \citep{gladyshev2008massive, butterfield2000bangiomorpha}. This raises the question: what is so good about sex?

In asexually reproducing species, all descendants of an organism are nearly clones, up to mutations within the lineage. Being permanently locked together gives the genes strong influence on each other. Selection can't act on one gene without dragging on the others. For example, suppose there are two genotypes within an asexual population, carrying different alleles at each of two different loci, as a result of mutations. One of the loci is currently fitness-neutral while the other is subject to selection pressure. The selection pressure tends to cause one of these genotypes to outcompete the other, eliminating one variant at the neutral locus. In other words, tight linkage between genes puts direct downward pressure on genetic diversity \citep{charlesworth1993effect, hudson1995deleterious}. Additionally, if two different beneficial mutations arise in two different organisms, they compete with each other. The only way for a single organism to obtain both beneficial mutations is if one arises again within the subpopulation that already carries the other, which is unlikely and therefore slow \citep{hill1966effect, felsenstein1974evolutionary, weismann1889essays, fisher1930genetial, muller1932some, crow1965evolution}. Conversely, if a deleterious mutation arises, all of the other genes in that lineage are stuck with it forever -- unless there is a reverse mutation, which is rare \citep{keightley2006interference, muller1932some}. An asexual species has rigid rather than flexible interaction between genes: it overcommits to particular genetic arrangements.

Sexual reproduction is a boundary that softens the rigid interactions between genes. It frequently breaks up the relationships between genes, assembling them into new genomes, effectively saying, ``don't get overconfident in that genetic arrangement; hold each arrangement more lightly". Aspects of the genome that work well are propagated, like sodium ions gated into a neuron during an action potential, and poorly-working aspects are discarded. Sex contextualizes genetic arrangements. 

Boundaries encourage lightly-held, modular interactions. By not overcommitting to a particular genome, sex encourages genes to flexibly interact with other genes \citep{livnat2008mixability, livnat2010sex, wagner1996perspective, holland1975adaptation,dawkins1976selfish, clune2013evolutionary}. Instead of being overfit to a particular context, genes develop a robust identity that's both independent and inter-functional. Recombination puts genes under pressure to evolve a generalized, grounded wisdom that reflects the structure of the world, like a person learning multiple languages and extracting the underlying commonalities. At the same time, because each gene is always operating in the presence of other genes, it develops its own distinct point of view that adds unique value to a genome.




\subsection{Cognitive control}

A broad class of boundaries on particular drives, goals and strategies is \textit{cognitive control} \citep{botvinick2001conflict, braver2012variable, miyake2000unity, miller2001integrative}. In the case of overeating, control contextualizes the food-seeking drive. In the case of the chickens, control contextualizes the prepotent tendency to approach the food. In the case of over-focusing on a single goal like work, control helps with task switching.  Cognitive control, when functioning well, is a semi-permeable boundary: it does not erase particular goals, but instead contextualizes them within a larger system.

Semi-permeable boundaries like cognitive control situate myopic goals and frames within a larger context. I might work obsessively on a project while also having a rule that I must go to bed at 10 pm. This boundary doesn't block me from temporarily taking a strong perspective, but it does place contextual limits on it. With this kind of intelligent boundary, different ideas are kept distinct but can also be called upon appropriately and related to one another \citep{hatano1984two, tetlock1986value, herzog2014harnessing, gigerenzer2011heuristic}. 

Boundaries also translate the pressure of motivation into higher-order structure. When nothing stops a particular drive or goal or strategy from dominating behavior, it tends to follow a shortest path defined under its own myopic understanding of the world. For example, the chickens in Section 1.1 wanted food and tried to take the shortest path toward it in the naive sense of a straight line through space. In the backwards world created by the experimenter, this action does not accomplish the deeper goal of reaching food, for which moving spatially toward food is only a proxy. The chicken's motivation is short-circuited: it expends energy without making progress on the deeper goal. Humans can easily solve the task by inhibiting their prepotent tendency to approach food. The boundary of control breaks the symmetry of congruent action. In general, semi-permeable boundaries promote formation of new structure by placing contextualizing limits.


\subsection{Information in the brain}

\begin{center}
\textit{`Memory is not an average of experience.'}\\*David Marr
\end{center}


The brain miraculously keeps many pieces of information distinct from one another. If you picture a highly connected network of neurons with their signals continually impinging on one another, it's not obvious that this would be an easy thing to accomplish. In this section, we review a selected handful of mechanisms by which the brain maintains semi-permeable boundaries between different signals. Each paragraph below focuses on one of these mechanisms. There are many more that we do not cover. The brain is perhaps the most extraordinary example in nature of a system of semi-permeable boundaries supporting the proliferation of multitudinous forms that develop their own richly distinct identities yet are also meaningfully linked together.

Lateral inhibition is a central tenant of neural organization \citep{isaacson2011inhibition, hubel1962receptive, douglas2004neuronal}. Lateral inhibition means the activity of a neuron is reduced when its neighbors are active. This segregates information to create and sustain distinct neural representations. Lateral inhibition was first studied in the nerve cells of the eye, where it enhances contrast at the edges of stimuli \citep{hartline1956inhibition}. When a photoreceptor in the retina is activated by light, it sends signals forward toward the brain; but it also activates inhibitory interneurons, which suppress adjacent photoreceptors and their downstream targets. This amplifies the perception of borders and contours. And the same principle operates throughout the brain. In visual cortex, for example, inhibition sharpens selectivity of neurons for abstract visual features like the orientation of a line \citep{sillito1975contribution}. 

% Global inhibition also supports the existence of distinct forms. In the hippocampal formation and connected areas, some cells are tuned to particular directions the animal's head could be facing. Inhibition creates a winner-take-all effect, integrating over intermittent noisy evidence (like vestibular signals when the head turns) to create a single stable representation of the head direction \citep{zhang1996understanding, rolls2022attractor}. Inhibition prevents the signals in some channels from getting blended or overwritten by the signals in other channels. 

The brain uses inhibition organized into oscillatory dynamics to keep memory items separated \citep{lisman2013theta, jensen2010shaping, roux2014working, klimesch2007eeg}. Distinct items fire at different phases of the 8-12 Hz alpha oscillation. The inhibitory phase of the alpha rhythm silences all but one item at any given moment. By segregating firing in phase space, multiple memories are held simultaneously without interference. 

The circuit architecture of hippocampus separates experiences or concepts into distinct representations, avoiding interference between similar memories \citep{mcclelland1995why, marr1971simple, mcnaughton1987hippocampal, treves1994computational, muller1987effects, leutgeb2007pattern, colgin2008frequency}. Inputs from entorhinal cortex are distributed via mossy fibers to a much larger population of dentate gyrus granule cells, creating sparse, orthogonal codes in dentate gyrus. This way, situations or ideas that are superficially similar but functionally different are kept cleanly separated in neuronal activity space -- a unique neural fingerprint for each distinct concept or memory. This prevents, for example, yesterday's memory of where you parked your car from interfering with today's memory of where you parked your car in the same parking ramp. 

Compared to other animals, the human brain especially attempts to discretize its experience into approximately symbolic representations \citep{dehaene2022symbols, touretzky1988distributed, smolensky1990tensor, behrens2018cognitive}. The capacity to separate things into nearly-discrete entities and then recombine them in vast numbers of structured ways powers the extraordinary human capacity for reasoning \citep{fodor1975language, pinker1994language, lake2015human, chomsky1957syntactic, kurth2023replay}. Semi-permable boundaries keep forms distinct while enabling them to flexibly and modularly interact. Like genes participating in many genomes, discretized neural representations participate in many structured combinations. This encourages each entity to develop an identity that both is distinct and also reflects a more generalized picture of the world.

More broadly, healthy brain dynamics live at a sweet spot between excessively stable synchronized patterns and chaotic uncorrelated noise \citep{beggs2003neuronal, chialvo2010emergent, tognoli2014metastable, deco2011emerging, bak1987self, shew2011information, rabinovich2008transient, haldeman2005critical, kotler2025pathfinding}. In this regime, the brain has access to a huge repertoire of patterns it can explore temporarily without overcommitting or getting stuck. 

Loss of dynamic flexibility, where the brain's activity becomes more stereotyped and no longer explores as wide a repertoire of states, is tied to lower cognitive performance \citep{garrett2013bold, grady2014understanding, cocchi2017criticality, muller2025critical, shew2009neuronal}. More extreme stereotypy corresponds to severe dysfunction. For example, in Parkinson's disease, basal ganglia and cortical circuits collapse into excess synchrony and lose the flexibility needed to guide nuanced motor outputs \citep{hammond2007pathological, brown2003rhythmic}. 


\subsection{Interpersonal dynamics}

\begin{center}
\textit{`Stand together yet not too near together, as the oak tree and the cypress grow not in each other's shadow.'}\\*Kahlil Gibran
\end{center}


Psychoanalysis introduced the concept of `boundaries' in human psychology, distinguishing what is the self from what is outside or other \citep{federn1928narcissism, tausk1919entstehung}. Early works applied the concept to psychosis, where those boundaries were thought to be blurred. But the need for clear self-other boundaries was also thrown into relief by the intimacy of the therapeutic relationship. In complex internal territory, it became harder to disentangle which experiences really belonged to someone and which were attributed in imagination by the other person \citep{freud1894neuro, freud1910future}. Analysts risked harming patients by imposing their own beliefs and desires, even to the extent of sexual abuse or psychological domination \citep{gabbard1995boundaries}. 

The concept was enriched by Gestalt therapists, who agreed that boundaries can be too permeable; but added that they can also be too rigid, causing isolation and stagnation \citep{perls1951gestalt, polster1974gestalt, yontef1993awareness}. Family systems theorists and subsequent work further emphasized that lack of boundary in close relationships leads to enmeshment and loss of autonomy, while excessively rigid boundaries lead to isolation \citep{minuchin1974families, bowen1978family, cloud1992boundaries, brown2012daring}. In attachment theory, people with an anxious attachment style struggle to set boundaries for fear of alienating others, while people with an avoidant attachment style develop overly rigid and isolating boundaries \citep{ainsworth1978patterns}. Strengthening the agency of the self through semi-permeable boundaries is foundational for psychological health: meaningful connection with other people while preserving integrity of the self. 

As with other living systems, humans have a rich array of psychological boundaries, with intelligence in their nuance. Anger, historically often viewed as sinful and irrational, is now seen as part of our system of boundaries: an important signal that our integrity is being violated \citep{lerner1985dance, videbeck2010psychiatric, sell2011recalibrational}. Healthy shame is suggested to operate as a bound on our own selfishness \citep{bradshaw1988healing}. Some psychologists argue that the incest taboo reroutes desires, which would otherwise be short-circuited, into productive activity \citep{stein1973incest, levistrauss1949structures, freud1913totem}. Assertiveness forms a boundary against the drives of other individuals \citep{smith1985say}. Skepticism protects us from credulity and having our own experience overwritten by the assertions of others \citep{lewandowsky2012misinformation, sperber2010epistemic}. Boundaries take many forms and continue to evolve as we learn across our lifetime.

% great example is the imaginations we have about other people's views of us. 

Without boundaries, interactions tend to result in one person being dominated by another: a patient's own beliefs replaced with those of an analyst, or the desires of one person in a relationship ignored. With semi-permeable boundaries, we have rich internal worlds. We are sensitive to each other, but there is also enough space for our internal experience to flourish without being immediately overwritten by external signals. Our internal experience is contextualized in relationship to other individuals, creating new structure: mutual understandings, relationships, communities, cultures. 

\subsection{Contemplative practice}

\begin{center}
\textit{`The world is perfect as it is, including my desire to change it.'}\\*Ram Dass
\end{center}


Awareness is contextualization. Think of an assumption somebody has that's never been questioned. That assumption could be lifelong and self-defining, or it could be fleeting and perceptual, like the assumption that the thing I'm touching is a keyboard. Unquestioned assumptions are overcommitment. Within their own frame, they have a kind of tautological truth, a near-absolute formality. But sometimes there's a moment of stepping back, where the assumed form becomes an object in awareness. In that moment, the assumption is contextualized. We realize it's not an absolute truth standing alone, but rather a form in our minds. 

Contemplative traditions suggest that the only `absolute' truth is the self-evident truth of immediate experience -- awareness itself. Of course, the concept of awareness is incomplete. Once we picture awareness as an object, it's not the thing we're talking about. So the word `truth' is not really describing any particular thing at all.  By construction, contextualization is an unsolvable mystery from any particular point of view. 

% We could use different language and describe it as something more like an orientation toward stepping back from each perspective into awareness. And again, any concept we have of that process is not what we're really talking about.

Awareness is an evolving system of boundaries: it limits overcommitment to any thing. What it takes to limit overcommitment to A is different than what it takes for B, so new boundaries are needed as the situation changes. This will be relevant for AI alignment in the next section. The boundaries of awareness are semi-permeable because they don't reject the form they contextualize. Becoming aware of a belief doesn't make the belief within its own frame wrong in an absolute sense any more than it was right in an absolute sense. Awareness holds us at the knife's edge of not collapsing exclusively into any particular forms. This activates a deeper sensitivity to our own livingness and to the world. Subtler forms, which would have been erased by overcommitment to other forms, instead play a role in a richer overall internal structure. Our own potential within the world creatively emerges in continued newness. 

Contemplative philosophy posits that suffering comes from overcommitment to particular conceptualizations or desires: believing excessively in a formalism. Being attached to particular concepts, beliefs, feelings and other patterns in a collapsed way. There's always something we believe, something we can't even see as an object because it's so tautological for us. We keep trying to give ourselves what we think we want under this model, pretending that things are formalizable, but as a result we become less sensitive to the rest of the world. The parts of the world not covered by our concepts subjectively appear terrifying or morally wrong. And what we do to prevent the tautologically bad thing from happening is inevitably what causes the bad thing to continue. In other words, our collapsed patterns hold the tension that paradoxically creates the unease they resist. These are, by construction, the patterns that persist. From one point of view, this is the problem of suffering; from another point of view, it is all the beauty and meaningfulness of the world.

% \footnote{Some schools of thought go a step farther to observe that whatever our current self is, it is always already inevitably contextualized, and love has no opposite.}

Awareness contextualizes these dynamics. Stepping back into awareness can feel infinitely scary from the original frame, because it's allowing the tautologically bad thing. But from the new frame, the bad thing is just another content of experience. The fear or wrongness of not-self is no longer an absolute but exists in context. So awareness brings healing and growth. People often report subjectively that the energy locked in the darkness turned out to be full of life, and that there's something self-evidently good or beautiful about participating in this mysterious discovery of new structure and relationship. 

The orientation toward not overcommiting to particular forms within experience is familiar in art, poetry, music, dance. The meaning of art is open-ended and changes with context -- it has an inner life. What we value is perhaps something about the subtlety and the resistance art has to being pinned down into a formalism. It moves us.


\section{The depth of life}


% Adam Frank's book about how science overindexes on disembodied abstractions, while the real world, grounded in direct experience, is always something more \citep{frank2023blind}.


\subsection{Groundedness}


While our conscious concepts fit the world at one level, unconscious processing shapes much of our behavior, the anatomy of our bodies encodes another kind of intelligence, our enzymes fit the world at a smaller scale, and in an evolvability sense our genes anticipate future selection challenges.

Lifeforms have been faced with an incomprehensibly vast number of kinds of problems and explored combinatorially many partial solutions -- within a cell, within an organism, across a population. 

Ken Stanley started with simple random images, like a couple of curvy lines. He asked people to rate the pictures for interestingness. The most interesting ones were then bred together, and this process of evolution was carried on for many steps. What eventually came out was images with a lot of richness and semantic meaning, which looked like a face or a fish or a moonrise \citep{secretan2008picbreeder}. In related experiments with navigation and physics-based tasks, the researchers found that bottom-up search for interesting components was more effective than top-down optimization for a pre-defined objective \citep{lehman2011abandoning}. In other words, if you deliberately try to make structures like this, it's paradoxically harder to get them to happen. If you overcommit to optimizing for one formal idea, it leads to collapse \citep{kumar2025questioning}. But when humans draw on their own light, playful ideas of what is interesting, it grounds the search in countless little nuances from evolution (e.g. in our visual system and our motivational system) and from our lifetime of experience with the real world.

Author Lisa Stardust claims that ``the moon controls the tides of the ocean, and we are made of 60 percent water. This means that the moon has a huge effect on all of us" \citep{mitchell2021moonwater}. You probably immediately spotted the flaw in this argument. But at a zeroth order level, the argument does make perfect sense: W impacts X, X is made of Y, Z is also made of Y, so W should impact Z. Overriding this logic requires a higher order correction term: tides arise from differential tugging over long distances in a body of water that is free to slosh around. Adding the correction term is an increase in subtlety. Subtle correction terms are often hard-won knowledge originating from thoughtful interactions with the world. But we only profit from those interactions if we accept that our current model isn't the final answer\footnote{Boundaries also protect Stardust's mystic beliefs. Boundaries create space for the mystic frame to explore its own reality. Stardust doesn't know a priori how right or wrong the mystic frame is; sometimes we need space to explore ideas everyone else thinks are crazy, like heliocentrism. Even \textit{after} Stardust discovers that the mystic frame doesn't do well predicting a large class of sensory evidence, she can still hold it as a frame that has some value -- perhaps it resonates with some internal psychological structure, like Jungian archetypes. If nothing else, remembering the internal logic of that frame might help her empathize with others who believe it. Contextualization holds the mystic frame for what it is, while simultaneously understanding that the Newtonian explanation is better for launching projectiles.}. As our ideas are tested against multiple situations and problems, they are refined and take on some of the deep structure of the world, a grounded wisdom.


\subsection{Livingness before life}

Each lifeform we see today is a continuation of background momentum, building up from simpler but already incredibly rich processes which are themselves exquisitely contextualized to their surroundings. 

Life is that it rides on top of a world-deep wave of semi-stable dynamics. The universe is full of all kinds of rich dynamical processes outside of what we call `life' -- including protons, chemistry, nebulae, snowflakes. Earth's livingness at a geophysical level (plate tectonics, tides, volcanism, magnetism, mineral cycles, water cycles, prebiotic chemistry and so on) formed the foundation for the layer of dynamics we call life \citep{smith2016origin, hazen2010mineral, stern2024importance, nisbet2001habitat, sleep2010hadean}. For example, the weathering of newly formed rocks made minerals available for life. In some theories, the cyclic proto-metabolic chemistry of deep sea vents was the dynamical substrate that emerging life rode on top of \citep{baross1985submarine, wachtershauser1988before, martin2008hydrothermal}. When robust plate tectonics started about a billion years ago, this change likely favored more complex life in response to the new niches and dynamic selection pressures \citep{frank2024find}. What we think of as life is a smooth continuation from the rich systems of the universe as they continue to unfold \citep{bregman2020humankind, virgo2011elongation, nowak2008prevolutionary}.

In other words, evolution is the process that gives rise to life, not something that happens after life exists. A kind of `life force' from the statistical pressure of autocatalytic cycles and combinatorial symbiogenesis \citep{aguerayarcas2024computational}. Related is Michael Wong's paper that generalizes evolution to non-living systems \citep{wong2023roles}. Evolution before genes \citep{vasas2012evolution}. Some technology can even be thought of as having a kind of livingness \citep{bedau2010living}, which is tied to the rest of the world.

% Michael Levin's cells doing living computation.



\subsection{Evolvability and modularity}

\begin{center}
\textit{`To create is to recombine.'}\\*François Jacob
\end{center}

Evolution of evolvability, meta-learning and multilevel selection. Evolution is an optimization algorithm, like gradient descent. When it operates on many different challenges over time, it will discover general solutions that themselves are optimization algorithms. So the genome itself encodes a rich learning model of the world. One very obvious aspect of this is the kind of learning we study in psychology. But it must exist at all levels. The genome itself can be `model-based', anticipating the future \citep{watson2016can}. Rather than thinking of the genome as encoding some kind of static phenotype (hair color, height), we can think of it encoding this intrinsically intelligent learning/planning system.  

The discovery of sex is a great example of evolution not only driving direct adaptation to the environment but also driving the capacity to adapt better in the future. Sex enhances evolvability. In machine learning, this is called meta-learning. Evolution learns how to learn \citep{wagner1996perspective, olah2021analogies}. 


\section{An aligned future}

\begin{center}
\textit{`We can love the beautiful, and believe in it, and thereby open ourselves to an understanding of love that does not dominate, but cherishes the independence and beauty of the loved.'}\\*Martha Nussbaum
\end{center}

What does the opposite of overcommitment look like in a future shaped by AI? In living systems, evolving semi-permeable boundaries contextualize partial forms to be more long-sighted in time and space, increasing subtlety. Part of what we value, in the deeper sense, is that whatever form we have for what we value right now does not place hard limits on the future.

The point of alignment is not to say that any particular perspective is absolutely wrong or right. An aligned future will include continual reinvention of whatever concepts we have, even down to the assumptions those concepts are built on, and the assumptions those assumptions are built on. We want AI to respect the livingness of the world and be aligned with it. But how can we align to something we can't pin down?

One way to look at this is the existence of healthy, adaptive semi-permeable boundaries at all scales. Of course, many boundaries already exist. Most safety methods can be viewed as boundaries, including safety post-training, guardrail models, red teaming, mechanistic interpretability, government oversight and so on \citep{gabriel2025ethics}. Here are some other kinds of boundaries:

\textbf{The boundaries of physics.} If life is spread across many light years -- assuming we don't discover physics allowing faster than light communication -- then the sheer time of communication imposes a boundary. This could preserve diversity between different forms. For example, if one solar system goes awry, others might have time to devise strategies to contain it. If this kind of barrier is necessary, then AI might indeed explain the Fermi paradox, because leaving a planet is so much greater than previous technological challenges. The reality that we probably cannot spread our civilization over many light years before AI exceeds human intelligence suggests that we must look to different kinds of boundaries, and hope that they are sufficient. 

\textbf{Boundaries in social systems.} How do we encourage wisdom in the development of AI? How much of this will come from having different perspectives on the problem among people, and how does this relate to the extensive communication between researchers that characterizes the way science and engineering are done today? Boundaries in communication between different AI researchers? Preservation of human culture (anywhere from an ethnic or national level, to the cultures of different research labs), from which fundamentally new ideas for AI development might be unexpectedly drawn? Maintaining global conceptual diversity. How about boundaries in our own use of AI? How do we avoid over-using it or ceding too much cognitive responsibility?

\textbf{Boundaries within ourselves.} How can we ourselves, both as AI researchers and as humans participating in the social systems AI is becoming part of, keep stepping back and contextualizing our own reality? This could be at an almost mystical level of self-awareness and discovery, but it could also be at a very mundane level like 

\textbf{Boundaries within AI systems.} At a technical level, we have agents with different aims and knowledge (eg through personalization, but also from different labs, different nations and so on); sub-parts of a model with lower bandwidth between them (eg conditional computation); instances kept separate by not sharing context; perhaps memories or parts of representation space kept separate by design or emergently through learning. At a more abstract level, what does it mean for an AI system to keep stepping back from whatever was previously axiomatic, and instead holding it as an object? Is there a version of AI that can continually contextualize its own processes as partial truths? What would it mean for AI to continually release from exclusive attachment to any particular form? How can we protect the potential for even \textit{that} conceptualization to be contextualized in the future?

Another key ingredient is bringing to bear the boundaries that already exist in life. The staggering richness of the boundaries instantiated in existing life. If a boundary is itself formal, it's not much of a boundary. Grounded in the full depth of life.

% Alignment is dynamic because new boundaries are always needed as the optimizing forces in the world change.

Through innumerable interactions and grounded experiments over billions of years, biological life has become fractally complex with traces of the rest of the world imprinted on each part. Boundaries support the `performance' of life, while preventing runaway loops that lead to the overcommitment of excess narrow performance. Likewise, more aligned AI is also more performant, to the extent that the kind of performance we're looking for respects the subtlety of life. 


New things have been arising in the universe for a long time. A billion years ago there were no plants. Four years ago there was no ChatGPT. What's on our minds collectively as a society, what we understand, the lenses we use to look at the world, keep changing. The subjective experience of what it's like to be me keeps changing too. Paradox is fundamentally how we as humans grow. There's a clash between the interiority of our current particular perspective, versus the awareness of this as simply another perspective. That's the essence of true AI alignment.

Alignment is not picking the right values or principles, or even the right system for learning them. It is not any method for interpretability or keeping humans in the loop. All of these can be useful parts of alignment. But alignment itself is the continued dance of contextualizing any particular form. It is the orientation of holding forms lightly, neverendingly stepping back into perspectives that contextualize what previously seemed to be real (including the concept of `holding forms lightly'). 

To reiterate the point we've made several times throughout the paper: the universe is nothing but form. The point of alignment is not to avoid form. If you want, you could think of any form as small-scale lock-in or overcommitment. But the direction is toward contextualization and potential. The lens we propose in this paper, of `misalignment as overcommitment', is itself a myopic form. Alignment intrinsically cannot be fully understood. 

In a life-like way, AI can continue to develop beautiful and meaningful new structure even when it has far surpassed humans. Humans continually evolve what we believe, even our self-definition. With nuanced boundaries, beliefs release into larger awareness without being lost or erased. This is the kind of dynamic we envision for healthy AI systems. A future where someone who far transcends our understanding and morals will be pleased with it. Rather than prescribing a particular conceptualization of what an AI should do, it participates in ongoing cycles of subtler boundary formation and releasing into contextualization, creating deeper relationship with the rest of the world.




\section{Objections}

Q: Is this pure relativism? Everything is equal, you can't tell anything apart? If the only form of alignment is placing limits on AI doing any particular thing too much, then wouldn't it equally prefer human welfare as smallpox welfare?

A: All these local perspectives are vitally important. It makes perfect sense that humans would want to advantage our own welfare. Semi-permeable boundaries protect against overcommitment to a particular perspective, including relativism. They also allow some relativism when it's useful: for example, to the degree that it helps us appreciate the plurality of human values. AI comes into existence amid a profound network of existing reality which is saturated with meaning and importance. The point is to nourish all this form and structure, not to extinguish it. 

Q: Is this a scala naturae fallacy? 

A: There is something different about a universe with rich and subtle structure, versus a homogeneous sea of energy. This paper investigates what it means to align AI with the livingness of the world. You can interpret this as a value judgement about rich worlds being better than impoverished ones, or you can interpret it in a value-free way. 

Q: Is this accelerationism?

A: We're agnostic on pro-tech/anti-tech arguments. There's a possibility for disaster due to things moving too quickly, collapse of diversity, loss of groundedness. On the other hand, there's a possibility for flourishing with tech creating new niches. Whatever direction society takes with more or less rapid advances, we hope the principles in this paper will be relevant.

Q: Is this paper right-wing ideology? You're talking about barriers which reminds me of border walls. 

A: See next objection.

Q: Is this paper left-wing ideology? You're talking about diversity which reminds me of affirmative action. 

A: See previous objection.

Q: Are you describing a set of principles so abstract that you're effectively leaving all the actual work to other people? 

A: Yes, sorry.


% \begin{landscape}
% \begin{table}[p]
% \centering
% \footnotesize
% \begin{tblr}{
%   width=\linewidth,
%   colspec={|X[1.2,l]|X[1.0,l]|X[1.0,l]|X[1.2,l]|X[1.8,l]|},
%   colsep=4pt,
%   stretch=0,
%   row{1}={font=\bfseries},
%   hlines
% }
% Structured space & Force & Outcome without boundary & Semi-permeable boundary & Outcome if potential is held by boundary \\

% Competing drives and goals in an organism &
% Drive to eat &
% Obesity &
% Other drives, self-control, supportive environmental systems &
% Nutritional needs satisfied without overeating \\
% Complex ecosystem &
% Human drive for expansion &
% Resource depletion, mass extinction &
% Measured regulatory policy &
% Economic growth without extensive ecosystem destruction \\
% Individuals have different identities and motives &
% P's will to dominate &
% Loss of agency in Q &
% Owned anger in Q &
% Relating while maintaining individual autonomy \\
% An intricate, balanced economy &
% Profit motive of one company &
% Monopoly and reduced innovation &
% Laws that allow profit seeking within limits &
% Productive competition \\
% \hline
% Multiple perspectives within an individual &
% Diffusion and drive for simplicity &
% Collapse to rigid thinking &
% Recognition of uncertainty &
% Beliefs that are stable but also adaptive and evolving \\
% Distinct intra- and extra-cellular environments &
% Elecrochemical gradients &
% Dissolution of cell &
% Cell membrane &
% Cell maintains integrity but also processes external signals \\

% Orderly cell types and tissues &
% Mutation and selection on cell lineages &
% Cancer &
% DNA repair, tumor suppression &
% Cancer is minimized while mutations can still benefit immunity and germ-line evolution \\
% Individuals have different problem-solving methods &
% Social conformity, diffusion of ideas &
% Groupthink &
% Thinking separately before sharing results &
% Wisdom of crowds \\
% Rich array of representations in the brain &
% Diffusion to equilibrium &
% Blending of representations &
% Lateral inhibition &
% Separate representations exist but can also interact \\
% \end{tblr}
% \caption{Mapping some example systems into our terminology.}
% \label{tab:examples}
% \end{table}
% \end{landscape}





\section{Acknowledgements} 

Clark Potter for planting these ideas more than a decade ago. Zach Duer for comments on the manuscript.

\section{Competing Interests}

The authors declare no competing interests.

\bibliography{proxyfailure}

\end{document}
